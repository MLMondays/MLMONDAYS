<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Converting between YOLO and PASCAL-VOC object recognition formats, and creating a Tensorflow Dataset · &quot;ML Mondays&quot;</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="This blog post walks through the (somewhat cumbersome - I won&#x27;t lie!) process of converting between YOLO and PASCAL-VOC &#x27;bounding box&#x27; annotation data formats for image recognition problems."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Converting between YOLO and PASCAL-VOC object recognition formats, and creating a Tensorflow Dataset · &quot;ML Mondays&quot;"/><meta property="og:type" content="website"/><meta property="og:url" content="https://dbuscombe-usgs.github.io/MLMONDAYS/blog/2020/08/17/blog-post"/><meta property="og:description" content="This blog post walks through the (somewhat cumbersome - I won&#x27;t lie!) process of converting between YOLO and PASCAL-VOC &#x27;bounding box&#x27; annotation data formats for image recognition problems."/><meta property="og:image" content="https://dbuscombe-usgs.github.io/MLMONDAYS/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://dbuscombe-usgs.github.io/MLMONDAYS/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/MLMONDAYS/img/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://dbuscombe-usgs.github.io/MLMONDAYS/blog/atom.xml" title="&quot;ML Mondays&quot; Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://dbuscombe-usgs.github.io/MLMONDAYS/blog/feed.xml" title="&quot;ML Mondays&quot; Blog RSS Feed"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/MLMONDAYS/js/scrollSpy.js"></script><link rel="stylesheet" href="/MLMONDAYS/css/main.css"/><script src="/MLMONDAYS/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/MLMONDAYS/"><img class="logo" src="/MLMONDAYS/img/favicon.ico" alt="&quot;ML Mondays&quot;"/><h2 class="headerTitleWithLogo">&quot;ML Mondays&quot;</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/MLMONDAYS/docs/doc1" target="_self">Docs</a></li><li class=""><a href="/MLMONDAYS/docs/doc2" target="_self">Data</a></li><li class=""><a href="/MLMONDAYS/docs/doc3" target="_self">Models</a></li><li class=""><a href="/MLMONDAYS/docs/doc4" target="_self">API</a></li><li class=""><a href="/MLMONDAYS/help" target="_self">Help</a></li><li class="siteNavGroupActive"><a href="/MLMONDAYS/blog/" target="_self">Blog</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Recent Posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Recent Posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/10/14/blog-post">Converting makesense.ai JSON labels to label (mask) imagery for an image segmentation project</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/10/11/blog-post">Preparing a new dataset for an object recognition project</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/10/03/blog-post">ML terminology, demystified</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/10/01/blog-post">Creating a Tensorflow Dataset for an image segmentation task</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/09/15/blog-post">Making workflows reproducible</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="lonePost"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/MLMONDAYS/blog/2020/08/17/blog-post">Converting between YOLO and PASCAL-VOC object recognition formats, and creating a Tensorflow Dataset</a></h1><p class="post-meta">August 17, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/magic_walnut" target="_blank" rel="noreferrer noopener">Dan Buscombe</a></p></div></header><div><span><p>This blog post walks through the (somewhat cumbersome - I won't lie!) process of converting between YOLO and PASCAL-VOC 'bounding box' annotation data formats for image recognition problems.</p>
<p>The files we create using <code>makesense.ai</code> and downloaded in <code>YOLO</code> format with the <code>.txt</code> extension can be converted to the <code>PASCAL-VOC</code> format with the <code>.xml</code> extension. This blog post shows you how to do that with python. I also show you how to convert to a generic csv format that is also sometimes used. Finally, I show you how to convert your <code>PASCAL-VOC</code> format data into a Tensorflow <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TFRecord</a> that use <a href="https://developers.google.com/protocol-buffers/">Protocol buffers</a>, which are a cross-platform, cross-language library for efficient serialization of structured data.</p>
<h3><a class="anchor" aria-hidden="true" id="resources-i-used"></a><a href="#resources-i-used" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Resources I used</h3>
<p><a href="https://www.tensorflow.org/datasets/add_dataset">These</a> Tensorflow instructions for how to add a dataset, as well as some more specific Tensorflow object detection <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/preparing_inputs.md">workflows</a>, and finally the Tensorflow <a href="https://github.com/tensorflow/models">Model Garden</a>, which you'll use here. <a href="https://github.com/datitran/raccoon_dataset">This</a> and <a href="https://towardsdatascience.com/object-detection-tensorflow-854c7eb65fa">this</a> gave some outdated advice that was nevertheless useful, if not used here. <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">This</a> provides more details on TFRecords and their usages.</p>
<h3><a class="anchor" aria-hidden="true" id="first-dealing-with-empty-imageryannotations"></a><a href="#first-dealing-with-empty-imageryannotations" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>First, dealing with 'empty' imagery/annotations</h3>
<p>We first need to make sure there is a txt file for every image. Any <em>missing</em> .txt files are for images with no annotations (i.e. no people). So, we create an empty txt file with the right name if it is missing.</p>
<p>We only need two libraries for this:</p>
<pre><code class="hljs"><span class="hljs-keyword">import</span> os, glob
</code></pre>
<p>And one <code>for-loop</code> that iterates through each folder of images (<code>test</code>, <code>train</code>, and <code>validation</code> in the example below). If a certain .txt file is missing, it simply creates an empty one</p>
<pre><code class="hljs"><span class="hljs-keyword">for</span> cond in [<span class="hljs-string">'test'</span>, <span class="hljs-string">'train'</span>,<span class="hljs-string">'validation'</span>]:

    jpg = <span class="hljs-built_in">glob</span>.<span class="hljs-built_in">glob</span>(cond+<span class="hljs-string">'/*.jpg'</span>)

    <span class="hljs-keyword">for</span> <span class="hljs-keyword">f</span> in jp<span class="hljs-variable">g:</span>
       file_query = <span class="hljs-keyword">f</span>.replace(<span class="hljs-string">'jpg'</span>,<span class="hljs-string">'txt'</span>).replace(cond, cond+<span class="hljs-string">'_labels'</span>)
       <span class="hljs-keyword">if</span> os.path.isfile(file_query):
          pass
       <span class="hljs-keyword">else</span>:
          <span class="hljs-keyword">print</span>(<span class="hljs-string">"Creating %s"</span> % (file_query))
          with <span class="hljs-keyword">open</span>(file_query, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> fp:
             pass
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="second-yolo-to-pascal-voc-format-conversion"></a><a href="#second-yolo-to-pascal-voc-format-conversion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Second, YOLO to PASCAL-VOC format conversion</h3>
<p>PASCAL-VOC is a very common object recognition data format, probably more common than the YOLO format. Many example workflows will use either one of these two formats. Here we convert YOLO (<code>.txt</code>) format to PASCAL-VOC (<code>.xml</code>).</p>
<p>Let's set up the problem. Define an <code>IMG_PATH</code> containing jpg images (in the example below, called <code>test</code>), and a corresponding folder containing the associated .txt files (called <code>test_labels</code> below). This is what my file paths look like on my Linux box:</p>
<pre><code class="hljs"><span class="hljs-attr">IMG_PATH</span> = <span class="hljs-string">"/media/marda/TWOTB/USGS/SOFTWARE/MLMONDAYS/2_ObjRecog/test"</span>

<span class="hljs-comment"># txt_folder is txt file root that using makesense.ai rectbox</span>
<span class="hljs-attr">txt_folder</span> = <span class="hljs-string">"/media/marda/TWOTB/USGS/SOFTWARE/MLMONDAYS/2_ObjRecog/test_labels"</span>
</code></pre>
<p>We define a list of labels. We only have one label, <code>person</code></p>
<pre><code class="hljs">fw = os.listdir(IMG_PATH)
<span class="hljs-comment"># path of save xml file</span>
save_path = <span class="hljs-string">''</span> <span class="hljs-comment"># keep it blank</span>

labels = [<span class="hljs-string">'person'</span>]
global <span class="hljs-keyword">label</span><span class="bash">
label = <span class="hljs-string">''</span></span>
</code></pre>
<p>Some utilities:</p>
<pre><code class="hljs">def csvread(fn):
    <span class="hljs-keyword">with</span> <span class="hljs-keyword">open</span>(fn, <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> csvfile:
        list_arr = []
        reader = csv.reader(csvfile, delimiter=<span class="hljs-string">' '</span>)
        <span class="hljs-keyword">for</span> <span class="hljs-keyword">row</span> <span class="hljs-keyword">in</span> reader:
            list_arr.append(<span class="hljs-keyword">row</span>)
    <span class="hljs-keyword">return</span> list_arr

<span class="hljs-keyword">def</span> convert_label(txt_file):
    <span class="hljs-keyword">global</span> label
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-keyword">range</span>(<span class="hljs-keyword">len</span>(labels)):
        <span class="hljs-keyword">if</span> txt_file[<span class="hljs-number">0</span>] == <span class="hljs-keyword">str</span>(i):
            label = labels[i]
            <span class="hljs-keyword">return</span> label
    <span class="hljs-keyword">return</span> label
</code></pre>
<p>This is the code that extract the info from a YOLO record:</p>
<pre><code class="hljs">def extract_coor(txt_file, img_width, img_height):
    x_rect_mid = <span class="hljs-built_in">float</span>(txt_file[<span class="hljs-number">1</span>])
    y_rect_mid = <span class="hljs-built_in">float</span>(txt_file[<span class="hljs-number">2</span>])
    width_rect = <span class="hljs-built_in">float</span>(txt_file[<span class="hljs-number">3</span>])
    height_rect = <span class="hljs-built_in">float</span>(txt_file[<span class="hljs-number">4</span>])

    x_min_rect = ((<span class="hljs-number">2</span> * x_rect_mid * img_width) - (width_rect * img_width)) / <span class="hljs-number">2</span>
    x_max_rect = ((<span class="hljs-number">2</span> * x_rect_mid * img_width) + (width_rect * img_width)) / <span class="hljs-number">2</span>
    y_min_rect = ((<span class="hljs-number">2</span> * y_rect_mid * img_height) -
                  (height_rect * img_height)) / <span class="hljs-number">2</span>
    y_max_rect = ((<span class="hljs-number">2</span> * y_rect_mid * img_height) +
                  (height_rect * img_height)) / <span class="hljs-number">2</span>

    <span class="hljs-keyword">return</span> x_min_rect, x_max_rect, y_min_rect, y_max_rect
</code></pre>
<p>Loop through each file (in <code>fw</code>) and carry out the conversion, writing one <code>xml</code> format file for each <code>txt</code> file you have</p>
<pre><code class="hljs">for line <span class="hljs-keyword">in</span> fw:
    <span class="hljs-attr">root</span> = etree.Element(<span class="hljs-string">"annotation"</span>)

    <span class="hljs-comment"># try debug to check your path</span>
    <span class="hljs-attr">img_style</span> = IMG_PATH.split('/')[-<span class="hljs-number">1</span>]
    <span class="hljs-attr">img_name</span> = line
    <span class="hljs-attr">image_info</span> = IMG_PATH + <span class="hljs-string">"/"</span> + line
    <span class="hljs-attr">img_txt_root</span> = txt_folder + <span class="hljs-string">"/"</span> + line[:-<span class="hljs-number">4</span>]
    <span class="hljs-comment"># print(img_txt_root)</span>
    <span class="hljs-attr">txt</span> = <span class="hljs-string">".txt"</span>

    <span class="hljs-attr">txt_path</span> = img_txt_root + txt
    <span class="hljs-comment"># print(txt_path)</span>
    <span class="hljs-attr">txt_file</span> = csvread(txt_path)

    <span class="hljs-comment"># read the image  information</span>
    <span class="hljs-attr">img_size</span> = Image.open(image_info).size

    <span class="hljs-attr">img_width</span> = img_size[<span class="hljs-number">0</span>]
    <span class="hljs-attr">img_height</span> = img_size[<span class="hljs-number">1</span>]
    <span class="hljs-attr">img_depth</span> = Image.open(image_info).layers

    <span class="hljs-attr">folder</span> = etree.Element(<span class="hljs-string">"folder"</span>)
    folder.<span class="hljs-attr">text</span> = <span class="hljs-string">"%s"</span> % (img_style)

    <span class="hljs-attr">filename</span> = etree.Element(<span class="hljs-string">"filename"</span>)
    filename.<span class="hljs-attr">text</span> = <span class="hljs-string">"%s"</span> % (img_name)

    <span class="hljs-attr">path</span> = etree.Element(<span class="hljs-string">"path"</span>)
    path.<span class="hljs-attr">text</span> = <span class="hljs-string">"%s"</span> % (IMG_PATH)

    <span class="hljs-attr">source</span> = etree.Element(<span class="hljs-string">"source"</span>)

    <span class="hljs-attr">source_database</span> = etree.SubElement(source, <span class="hljs-string">"database"</span>)
    source_database.<span class="hljs-attr">text</span> = <span class="hljs-string">"Unknown"</span>

    <span class="hljs-attr">size</span> = etree.Element(<span class="hljs-string">"size"</span>)
    <span class="hljs-attr">image_width</span> = etree.SubElement(size, <span class="hljs-string">"width"</span>)
    image_width.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (img_width)

    <span class="hljs-attr">image_height</span> = etree.SubElement(size, <span class="hljs-string">"height"</span>)
    image_height.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (img_height)

    <span class="hljs-attr">image_depth</span> = etree.SubElement(size, <span class="hljs-string">"depth"</span>)
    image_depth.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (img_depth)

    <span class="hljs-attr">segmented</span> = etree.Element(<span class="hljs-string">"segmented"</span>)
    segmented.<span class="hljs-attr">text</span> = <span class="hljs-string">"0"</span>

    root.append(folder)
    root.append(filename)
    root.append(path)
    root.append(source)
    root.append(size)
    root.append(segmented)

    for ii <span class="hljs-keyword">in</span> range(len(txt_file)):
        <span class="hljs-attr">label</span> = convert_label(txt_file[ii][<span class="hljs-number">0</span>])
        x_min_rect, x_max_rect, y_min_rect, <span class="hljs-attr">y_max_rect</span> = extract_coor(
            txt_file[ii], img_width, img_height)

        <span class="hljs-attr">object</span> = etree.Element(<span class="hljs-string">"object"</span>)
        <span class="hljs-attr">name</span> = etree.SubElement(object, <span class="hljs-string">"name"</span>)
        name.<span class="hljs-attr">text</span> = <span class="hljs-string">"%s"</span> % (label)

        <span class="hljs-attr">pose</span> = etree.SubElement(object, <span class="hljs-string">"pose"</span>)
        pose.<span class="hljs-attr">text</span> = <span class="hljs-string">"Unspecified"</span>

        <span class="hljs-attr">truncated</span> = etree.SubElement(object, <span class="hljs-string">"truncated"</span>)
        truncated.<span class="hljs-attr">text</span> = <span class="hljs-string">"0"</span>

        <span class="hljs-attr">difficult</span> = etree.SubElement(object, <span class="hljs-string">"difficult"</span>)
        difficult.<span class="hljs-attr">text</span> = <span class="hljs-string">"0"</span>

        <span class="hljs-attr">bndbox</span> = etree.SubElement(object, <span class="hljs-string">"bndbox"</span>)
        <span class="hljs-attr">xmin</span> = etree.SubElement(bndbox, <span class="hljs-string">"xmin"</span>)
        xmin.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (x_min_rect)
        <span class="hljs-attr">ymin</span> = etree.SubElement(bndbox, <span class="hljs-string">"ymin"</span>)
        ymin.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (y_min_rect)
        <span class="hljs-attr">xmax</span> = etree.SubElement(bndbox, <span class="hljs-string">"xmax"</span>)
        xmax.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (x_max_rect)
        <span class="hljs-attr">ymax</span> = etree.SubElement(bndbox, <span class="hljs-string">"ymax"</span>)
        ymax.<span class="hljs-attr">text</span> = <span class="hljs-string">"%d"</span> % (y_max_rect)

        root.append(object)

    <span class="hljs-attr">file_output</span> = etree.tostring(root, <span class="hljs-attr">pretty_print=True,</span> <span class="hljs-attr">encoding='UTF-8')</span>
    <span class="hljs-comment"># print(file_output.decode('utf-8'))</span>
    <span class="hljs-attr">ff</span> = open('%s.xml' % (img_name[:-<span class="hljs-number">4</span>]), 'w', <span class="hljs-attr">encoding="utf-8")</span>
    ff.write(file_output.decode('utf-<span class="hljs-number">8</span>'))
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="third-create-a-tf-record-from-the-pascal-voc-data"></a><a href="#third-create-a-tf-record-from-the-pascal-voc-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Third, create a TF-RECORD from the PASCAL-VOC data</h3>
<p>The preferred way to carry out this procedure seems to change regularly, so it can be tricky to find out this information. Let's start by creating a new <code>conda</code> environment for this task, callled <code>tf_test_py36</code>, containing a specific version of python (my current go-to at the time of writing is 3.6 rather than the stable 3.7, because of dependency issues that can sometimes arise on Windows OS)</p>
<pre><code class="hljs">conda <span class="hljs-built_in">create</span> <span class="hljs-comment">--name tf_test_py36 python=3.6 tensorflow lxml contextlib2</span>
</code></pre>
<p>and activate:</p>
<pre><code class="hljs">conda <span class="hljs-built_in">activate</span> tf_test_py36
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="getting-tensorflow-garden-set-up"></a><a href="#getting-tensorflow-garden-set-up" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Getting Tensorflow Garden set up</h4>
<p>Clone the <a href="https://github.com/tensorflow/models/blob/master/official/README.md">Tensorflow Garden</a> GitHub repository:</p>
<pre><code class="hljs">git <span class="hljs-keyword">clone</span> <span class="hljs-title">https</span>://github.com/tensorflow/models.git
</code></pre>
<p>Add the top-level /models folder to your system Python path.</p>
<pre><code class="hljs">export PYTHONPATH=<span class="hljs-variable">$PYTHONPATH</span><span class="hljs-symbol">:/media/marda/TWOTB/USGS/SOFTWARE/models</span>
</code></pre>
<p>Install other dependencies:</p>
<pre><code class="hljs">pip install <span class="hljs-params">--user</span> -r official/requirements.txt
<span class="hljs-keyword">cd</span> research
protoc object_detection/protos/*<span class="hljs-string">.proto</span> <span class="hljs-params">--python_out=</span>.
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="create-the-tf-record"></a><a href="#create-the-tf-record" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Create the tf-record</h4>
<p>(Your current directory should be <code>models/research</code>)</p>
<p>This workflow is specific to the <code>POB</code> (People on Beaches) dataset that only has one label, so first, create a file called <code>object_detection/data/pob_label_map.pbtxt</code> and copy the following into it:</p>
<pre><code class="hljs"><span class="hljs-selector-tag">item</span> {
  <span class="hljs-attribute">id</span>: <span class="hljs-number">1</span>
  name: <span class="hljs-string">'person'</span>
}
</code></pre>
<p>Second, create a new file called <code>POB_images</code>, and copy all your jpg files and corresponding xml files into it - all together</p>
<p>Third, create a new file <code>object_detection/dataset_tools/create_pob_tf_record.py</code> and copy the following code into it. The variable <code>num_shards</code> is the number of pieces you'd like to create. It matters not for this dataset; we use 10.</p>
<pre><code class="hljs">from glob <span class="hljs-keyword">import</span> glob
<span class="hljs-keyword">import</span> hashlib, io, os, logging, random, re, contextlib2
from lxml <span class="hljs-keyword">import</span> etree
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> PIL.Image
<span class="hljs-keyword">import</span> tensorflow.compat.v1 <span class="hljs-keyword">as</span> tf

from object_detection.dataset_tools <span class="hljs-keyword">import</span> tf_record_creation_util
from object_detection.utils <span class="hljs-keyword">import</span> dataset_util
from object_detection.utils <span class="hljs-keyword">import</span> label_map_util

flags = tf.app.flags
flags.DEFINE_string(<span class="hljs-string">'data_dir'</span>, <span class="hljs-string">''</span>, <span class="hljs-string">'Root directory to raw pet dataset.'</span>)
flags.DEFINE_string(<span class="hljs-string">'output_dir'</span>, <span class="hljs-string">''</span>, <span class="hljs-string">'Path to directory to output TFRecords.'</span>)
flags.DEFINE_string(<span class="hljs-string">'label_map_path'</span>, <span class="hljs-string">'data/pet_label_map.pbtxt'</span>,
                    <span class="hljs-string">'Path to label map proto'</span>)
flags.DEFINE_integer(<span class="hljs-string">'num_shards'</span>, <span class="hljs-number">10</span>, <span class="hljs-string">'Number of TFRecord shards'</span>)

FLAGS = flags.FLAGS
</code></pre>
<p>The following is the main function that gets called to carry out the conversion. It creates a single <code>tf.Example</code> message (or protobuf), which is a flexible message type that represents a <code>{&quot;string&quot;: value}</code> mapping</p>
<pre><code class="hljs">def dict_to_tf_example(data,
                       label_map_dict,
                       image_subdirectory,
                       ignore_difficult_instances=False):
  <span class="hljs-string">""</span><span class="hljs-comment">"Convert XML derived dict to tf.Example proto.</span>

  Notice that this <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">normalizes</span> <span class="hljs-title">the</span> <span class="hljs-title">bounding</span> <span class="hljs-title">box</span> <span class="hljs-title">coordinates</span> <span class="hljs-title">provided</span></span>
  by the raw data.

  Arg<span class="hljs-variable">s:</span>
    dat<span class="hljs-variable">a:</span> dict holding PASCAL XML fields <span class="hljs-keyword">for</span> <span class="hljs-keyword">a</span> single image (obtained by
      running dataset_util.recursive_parse_xml_to_dict)
    label_map_dic<span class="hljs-variable">t:</span> A <span class="hljs-keyword">map</span> from <span class="hljs-built_in">string</span> label names <span class="hljs-keyword">to</span> integers ids.
    image_subdirectory: String specifying subdirectory within the
      Pascal dataset directory holding the actual image data.
    ignore_difficult_instance<span class="hljs-variable">s:</span> Whether <span class="hljs-keyword">to</span> skip difficult instances in the
      dataset  (defaul<span class="hljs-variable">t:</span> False).

  Return<span class="hljs-variable">s:</span>
    example: The converted <span class="hljs-keyword">tf</span>.Example.

  Raise<span class="hljs-variable">s:</span>
    ValueError: <span class="hljs-keyword">if</span> the image pointed <span class="hljs-keyword">to</span> by data[<span class="hljs-string">'filename'</span>] <span class="hljs-keyword">is</span> not <span class="hljs-keyword">a</span> valid JPEG
  <span class="hljs-string">""</span><span class="hljs-comment">"</span>
  img_path = os.path.<span class="hljs-keyword">join</span>(image_subdirectory, data[<span class="hljs-string">'filename'</span>])
  with <span class="hljs-keyword">tf</span>.gfile.GFile(img_path, <span class="hljs-string">'rb'</span>) <span class="hljs-keyword">as</span> fid:
    encoded_jpg = fid.<span class="hljs-keyword">read</span>()
  encoded_jpg_io = io.BytesIO(encoded_jpg)
  image = PIL.Image.<span class="hljs-keyword">open</span>(encoded_jpg_io)
  <span class="hljs-keyword">if</span> image.format != <span class="hljs-string">'JPEG'</span>:
    raise ValueError(<span class="hljs-string">'Image format not JPEG'</span>)
  key = hashlib.<span class="hljs-built_in">sha256</span>(encoded_jpg).hexdigest()

  width = <span class="hljs-keyword">int</span>(data[<span class="hljs-string">'size'</span>][<span class="hljs-string">'width'</span>])
  height = <span class="hljs-keyword">int</span>(data[<span class="hljs-string">'size'</span>][<span class="hljs-string">'height'</span>])

  xmins = []
  ymins = []
  xmaxs = []
  ymaxs = []
  classes = []
  classes_text = []
  truncated = []
  poses = []
  difficult_obj = []
  <span class="hljs-keyword">if</span> <span class="hljs-string">'object'</span> in dat<span class="hljs-variable">a:</span>
    <span class="hljs-keyword">for</span> obj in data[<span class="hljs-string">'object'</span>]:
      difficult = bool(<span class="hljs-keyword">int</span>(obj[<span class="hljs-string">'difficult'</span>]))
      <span class="hljs-keyword">if</span> ignore_difficult_instances <span class="hljs-built_in">and</span> difficul<span class="hljs-variable">t:</span>
        <span class="hljs-keyword">continue</span>
      difficult_obj.<span class="hljs-keyword">append</span>(<span class="hljs-keyword">int</span>(difficult))

      xmin = float(obj[<span class="hljs-string">'bndbox'</span>][<span class="hljs-string">'xmin'</span>])
      xmax = float(obj[<span class="hljs-string">'bndbox'</span>][<span class="hljs-string">'xmax'</span>])
      ymin = float(obj[<span class="hljs-string">'bndbox'</span>][<span class="hljs-string">'ymin'</span>])
      ymax = float(obj[<span class="hljs-string">'bndbox'</span>][<span class="hljs-string">'ymax'</span>])

      xmins.<span class="hljs-keyword">append</span>(xmin / width)
      ymins.<span class="hljs-keyword">append</span>(ymin / height)
      xmaxs.<span class="hljs-keyword">append</span>(xmax / width)
      ymaxs.<span class="hljs-keyword">append</span>(ymax / height)
      class_name = <span class="hljs-string">'person'</span> #get_class_name_from_filename(data[<span class="hljs-string">'filename'</span>])
      classes_text.<span class="hljs-keyword">append</span>(class_name.encode(<span class="hljs-string">'utf8'</span>))
      classes.<span class="hljs-keyword">append</span>(label_map_dict[class_name])
      truncated.<span class="hljs-keyword">append</span>(<span class="hljs-keyword">int</span>(obj[<span class="hljs-string">'truncated'</span>]))
      poses.<span class="hljs-keyword">append</span>(obj[<span class="hljs-string">'pose'</span>].encode(<span class="hljs-string">'utf8'</span>))

  feature_dict = {
      <span class="hljs-string">'image/height'</span>: dataset_util.int64_feature(height),
      <span class="hljs-string">'image/width'</span>: dataset_util.int64_feature(width),
      <span class="hljs-string">'image/filename'</span>: dataset_util.bytes_feature(
          data[<span class="hljs-string">'filename'</span>].encode(<span class="hljs-string">'utf8'</span>)),
      <span class="hljs-string">'image/source_id'</span>: dataset_util.bytes_feature(
          data[<span class="hljs-string">'filename'</span>].encode(<span class="hljs-string">'utf8'</span>)),
      <span class="hljs-string">'image/key/sha256'</span>: dataset_util.bytes_feature(key.encode(<span class="hljs-string">'utf8'</span>)),
      <span class="hljs-string">'image/encoded'</span>: dataset_util.bytes_feature(encoded_jpg),
      <span class="hljs-string">'image/format'</span>: dataset_util.bytes_feature(<span class="hljs-string">'jpeg'</span>.encode(<span class="hljs-string">'utf8'</span>)),
      <span class="hljs-string">'image/object/bbox/xmin'</span>: dataset_util.float_list_feature(xmins),
      <span class="hljs-string">'image/object/bbox/xmax'</span>: dataset_util.float_list_feature(xmaxs),
      <span class="hljs-string">'image/object/bbox/ymin'</span>: dataset_util.float_list_feature(ymins),
      <span class="hljs-string">'image/object/bbox/ymax'</span>: dataset_util.float_list_feature(ymaxs),
      <span class="hljs-string">'image/object/class/text'</span>: dataset_util.bytes_list_feature(classes_text),
      <span class="hljs-string">'image/object/class/label'</span>: dataset_util.int64_list_feature(classes),
      <span class="hljs-string">'image/object/difficult'</span>: dataset_util.int64_list_feature(difficult_obj),
      <span class="hljs-string">'image/object/truncated'</span>: dataset_util.int64_list_feature(truncated),
      <span class="hljs-string">'image/object/view'</span>: dataset_util.bytes_list_feature(poses),
  }

  example = <span class="hljs-keyword">tf</span>.train.Example(features=<span class="hljs-keyword">tf</span>.train.Features(feature=feature_dict))
  <span class="hljs-keyword">return</span> example
</code></pre>
<p>This portion does the file writing (i.e. creates the <code>.tfrecord</code> files from the collection of <code>tf.Example</code> records):</p>
<pre><code class="hljs">def create_tf_record(output_filename,
                     num_shards,
                     label_map_dict,
                     annotations_dir,
                     image_dir,
                     examples):
  <span class="hljs-string">""</span><span class="hljs-comment">"Creates a TFRecord file from examples.</span>

  Arg<span class="hljs-variable">s:</span>
    output_filename: Path <span class="hljs-keyword">to</span> where output <span class="hljs-keyword">file</span> <span class="hljs-keyword">is</span> saved.
    num_shard<span class="hljs-variable">s:</span> Number of shards <span class="hljs-keyword">for</span> output <span class="hljs-keyword">file</span>.
    label_map_dic<span class="hljs-variable">t:</span> The label <span class="hljs-keyword">map</span> dictionary.
    annotations_dir: Directory where annotation <span class="hljs-keyword">files</span> are stored.
    image_dir: Directory where image <span class="hljs-keyword">files</span> are stored.
    example<span class="hljs-variable">s:</span> Examples <span class="hljs-keyword">to</span> parse <span class="hljs-built_in">and</span> save <span class="hljs-keyword">to</span> <span class="hljs-keyword">tf</span> record.
  <span class="hljs-string">""</span><span class="hljs-comment">"</span>
  with contextlib2.ExitStack() <span class="hljs-keyword">as</span> tf_record_close_stack:
    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(
        tf_record_close_stack, output_filename, num_shards)
    <span class="hljs-keyword">for</span> idx, example in enumerate(examples):
      <span class="hljs-keyword">if</span> idx % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:
        logging.info(<span class="hljs-string">'On image %d of %d'</span>, idx, <span class="hljs-built_in">len</span>(examples))
      xml_path = os.path.<span class="hljs-keyword">join</span>(annotations_dir, <span class="hljs-string">'xmls'</span>, example.<span class="hljs-keyword">split</span>(<span class="hljs-string">'.jpg'</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">'.xml'</span>)

      <span class="hljs-keyword">if</span> not os.path.<span class="hljs-built_in">exists</span>(xml_path):
        logging.warning(<span class="hljs-string">'Could not find %s, ignoring example.'</span>, xml_path)
        <span class="hljs-keyword">continue</span>
      with <span class="hljs-keyword">tf</span>.gfile.GFile(xml_path, <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> fid:
        xml_str = fid.<span class="hljs-keyword">read</span>()
      xml = etree.fromstring(xml_str)
      data = dataset_util.recursive_parse_xml_to_dict(xml)[<span class="hljs-string">'annotation'</span>]

      <span class="hljs-keyword">try</span>:
        tf_example = dict_to_tf_example(
            data,
            label_map_dict,
            image_dir)
        <span class="hljs-keyword">if</span> tf_example:
          shard_idx = idx % num_shards
          output_tfrecords[shard_idx].<span class="hljs-keyword">write</span>(tf_example.SerializeToString())
      except ValueError:
        logging.warning(<span class="hljs-string">'Invalid example: %s, ignoring.'</span>, xml_path)
</code></pre>
<p>The <code>main</code> function reads all the jpg files in <code>POB_images</code>, as well as all the <code>xml</code> files in the same directory. Note that this could be set up differently, to read the <code>xml</code> files from a separate <code>annotations_dir</code>. The files are randomly shuffled. The number of training examples is 70% of the total, and the remaining 30% of files are used for validation. It then calls the <code>create_tf_record</code> function to create the <code>.tfrecord</code> set of 10 files.</p>
<pre><code class="hljs">def main(_):
  data_dir = FLAGS.data_dir
  label_map_dict = label_map_util.get_label_map_dict(FLAGS.label_map_path)

  logging.<span class="hljs-keyword">info</span>(<span class="hljs-string">'Reading from POB dataset.'</span>)
  image_dir = annotations_dir = os.path.<span class="hljs-keyword">join</span>(data_dir, <span class="hljs-string">'POB_images'</span>)

  examples_list = glob(image_dir+<span class="hljs-string">'/*.jpg'</span>)

  # Test images are <span class="hljs-keyword">not</span> included <span class="hljs-keyword">in</span> the downloaded data <span class="hljs-keyword">set</span>, so we shall <span class="hljs-keyword">perform</span>
  # our own split.
  random.seed(<span class="hljs-number">42</span>)
  random.shuffle(examples_list)
  num_examples = len(examples_list)
  num_train = <span class="hljs-type">int</span>(<span class="hljs-number">0.7</span> * num_examples)
  train_examples = examples_list[:num_train]
  val_examples = examples_list[num_train:]
  logging.<span class="hljs-keyword">info</span>(<span class="hljs-string">'%d training and %d validation examples.'</span>,
               len(train_examples), len(val_examples))

  train_output_path = os.path.<span class="hljs-keyword">join</span>(FLAGS.output_dir, <span class="hljs-string">'pob_train.record'</span>)
  val_output_path = os.path.<span class="hljs-keyword">join</span>(FLAGS.output_dir, <span class="hljs-string">'pob_val.record'</span>)

  # <span class="hljs-keyword">call</span> <span class="hljs-keyword">to</span> <span class="hljs-keyword">create</span> the training files
  create_tf_record(
      train_output_path,
      FLAGS.num_shards,
      label_map_dict,
      annotations_dir,
      image_dir,
      train_examples)

# <span class="hljs-keyword">call</span> again <span class="hljs-keyword">to</span> make the validation <span class="hljs-keyword">set</span>
  create_tf_record(
      val_output_path,
      FLAGS.num_shards,
      label_map_dict,
      annotations_dir,
      image_dir,
      val_examples)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
  tf.app.run()

</code></pre>
<p>And finally, run the script and make your tf-record format data ...</p>
<pre><code class="hljs">python object_detection/dataset_tools/create_pob_tf_record.py <span class="hljs-attribute">--label_map_path</span>=object_detection/data/POB_label_map.pbtxt  <span class="hljs-attribute">--data_dir</span>=`pwd` <span class="hljs-attribute">--output_dir</span>=`pwd`
</code></pre>
<p>This will create 10 files for the training data, and 10 for the validation set. You can now use these files to efficiently train a model using Tensoflow/Keras.</p>
<h3><a class="anchor" aria-hidden="true" id="optional-xml-to-csv"></a><a href="#optional-xml-to-csv" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>[OPTIONAL] XML to CSV</h3>
<p>Sometimes you also see people use object annotations in csv format. Luckily we can use the <code>xml</code> library to help carry out the data parsing, and <code>pandas</code> to easily convert to a dataframe, and then to a formatted csv file</p>
<pre><code class="hljs"><span class="hljs-keyword">import</span> os, glob
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> <span class="hljs-type">xml</span>.etree.ElementTree <span class="hljs-keyword">as</span> ET

def xml_to_csv(<span class="hljs-type">path</span>):
    xml_list = []
    <span class="hljs-keyword">for</span> xml_file <span class="hljs-keyword">in</span> glob.glob(<span class="hljs-type">path</span> + <span class="hljs-string">'/*.xml'</span>):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        <span class="hljs-keyword">for</span> member <span class="hljs-keyword">in</span> root.findall(<span class="hljs-string">'object'</span>):
            <span class="hljs-keyword">value</span> = (root.find(<span class="hljs-string">'filename'</span>).text,
                     <span class="hljs-type">int</span>(root.find(<span class="hljs-string">'size'</span>)[<span class="hljs-number">0</span>].text),
                     <span class="hljs-type">int</span>(root.find(<span class="hljs-string">'size'</span>)[<span class="hljs-number">1</span>].text),
                     member[<span class="hljs-number">0</span>].text,
                     <span class="hljs-type">int</span>(member[<span class="hljs-number">4</span>][<span class="hljs-number">0</span>].text),
                     <span class="hljs-type">int</span>(member[<span class="hljs-number">4</span>][<span class="hljs-number">1</span>].text),
                     <span class="hljs-type">int</span>(member[<span class="hljs-number">4</span>][<span class="hljs-number">2</span>].text),
                     <span class="hljs-type">int</span>(member[<span class="hljs-number">4</span>][<span class="hljs-number">3</span>].text)
                     )
            xml_list.append(<span class="hljs-keyword">value</span>)
    <span class="hljs-built_in">column_name</span> = [<span class="hljs-string">'filename'</span>, <span class="hljs-string">'width'</span>, <span class="hljs-string">'height'</span>, <span class="hljs-string">'class'</span>, <span class="hljs-string">'xmin'</span>, <span class="hljs-string">'ymin'</span>, <span class="hljs-string">'xmax'</span>, <span class="hljs-string">'ymax'</span>]
    xml_df = pd.DataFrame(xml_list, <span class="hljs-keyword">columns</span>=<span class="hljs-built_in">column_name</span>)
    <span class="hljs-keyword">return</span> xml_df

</code></pre>
<p>Then use like this:</p>
<pre><code class="hljs">image_path = os.path.join(os.getcwd<span class="hljs-literal">()</span>,'test_labels_xml')
xml_df = xml<span class="hljs-constructor">_to_csv(<span class="hljs-params">image_path</span>)</span>
xml_df.<span class="hljs-keyword">to</span><span class="hljs-constructor">_csv('<span class="hljs-params">test_labels</span>.<span class="hljs-params">csv</span>', <span class="hljs-params">index</span>=None)</span>
</code></pre>
</span></div></div><div class="blogSocialSection"></div></div><div class="blog-recent"><a class="button" href="/MLMONDAYS/blog/">Recent Posts</a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/MLMONDAYS/" class="nav-home"><img src="/MLMONDAYS/img/favicon.ico" alt="&quot;ML Mondays&quot;" width="66" height="58"/></a><div><h5>Internal links</h5><a href="/MLMONDAYS/docs/en/doc1.html">Docs</a><a href="/MLMONDAYS/docs/en/doc2.html">Data</a><a href="/MLMONDAYS/docs/en/doc3.html">Help</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://www.usgs.gov/centers/cdi" target="_blank" rel="noreferrer noopener">USGS Community for Data Integration (CDI)</a><a href="https://www.usgs.gov/centers/pcmsc/science/remote-sensing-coastal-change?qt-science_center_objects=0#qt-science_center_objects" target="_blank" rel="noreferrer noopener">USGS Remote Sensing Coastal Change Project</a><a href="https://www.danielbuscombe.com" target="_blank" rel="noreferrer noopener">www.danielbuscombe.com</a></div><div><h5>More</h5><a href="/MLMONDAYS/blog">Blog</a><a href="https://github.com/dbuscombe-usgs/DL-CDI2020">GitHub</a><a class="github-button" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a><div class="social"><a href="https://twitter.com/magic_walnut" class="twitter-follow-button">Follow @magic_walnut</a></div></div></section><a href="https://mardascience.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/MLMONDAYS/img/dash-logo-new.png" alt="Marda Science" width="170" height="45"/></a><section class="copyright">Copyright © 2020 Marda Science, LLC</section></footer></div><script>window.twttr=(function(d,s, id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return t;js=d.createElement(s);js.id=id;js.src='https://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js, fjs);t._e = [];t.ready = function(f) {t._e.push(f);};return t;}(document, 'script', 'twitter-wjs'));</script></body></html>