<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Creating a Tensorflow Dataset for an image segmentation task · &quot;ML Mondays&quot;</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="### Use case"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Creating a Tensorflow Dataset for an image segmentation task · &quot;ML Mondays&quot;"/><meta property="og:type" content="website"/><meta property="og:url" content="https://dbuscombe-usgs.github.io/MLMONDAYS/blog/2020/10/01/blog-post"/><meta property="og:description" content="### Use case"/><meta property="og:image" content="https://dbuscombe-usgs.github.io/MLMONDAYS/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://dbuscombe-usgs.github.io/MLMONDAYS/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/MLMONDAYS/img/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://dbuscombe-usgs.github.io/MLMONDAYS/blog/atom.xml" title="&quot;ML Mondays&quot; Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://dbuscombe-usgs.github.io/MLMONDAYS/blog/feed.xml" title="&quot;ML Mondays&quot; Blog RSS Feed"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/MLMONDAYS/js/scrollSpy.js"></script><link rel="stylesheet" href="/MLMONDAYS/css/main.css"/><script src="/MLMONDAYS/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/MLMONDAYS/"><img class="logo" src="/MLMONDAYS/img/favicon.ico" alt="&quot;ML Mondays&quot;"/><h2 class="headerTitleWithLogo">&quot;ML Mondays&quot;</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/MLMONDAYS/docs/doc1" target="_self">Docs</a></li><li class=""><a href="/MLMONDAYS/docs/doc2" target="_self">Data</a></li><li class=""><a href="/MLMONDAYS/docs/doc3" target="_self">Models</a></li><li class=""><a href="/MLMONDAYS/docs/doc4" target="_self">API</a></li><li class=""><a href="/MLMONDAYS/help" target="_self">Help</a></li><li class="siteNavGroupActive"><a href="/MLMONDAYS/blog/" target="_self">Blog</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Recent Posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Recent Posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/10/03/blog-post">ML terminology, demystified</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/MLMONDAYS/blog/2020/10/01/blog-post">Creating a Tensorflow Dataset for an image segmentation task</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/09/15/blog-post">Making workflows reproducible</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/09/01/blog-post">Creating a Tensorflow Dataset for an image recognition task</a></li><li class="navListItem"><a class="navItem" href="/MLMONDAYS/blog/2020/08/17/blog-post">Converting between YOLO and PASCAL-VOC object recognition formats, and creating a Tensorflow Dataset</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="lonePost"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/MLMONDAYS/blog/2020/10/01/blog-post">Creating a Tensorflow Dataset for an image segmentation task</a></h1><p class="post-meta">October 1, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/magic_walnut" target="_blank" rel="noreferrer noopener">Dan Buscombe</a></p></div></header><div><span><h3><a class="anchor" aria-hidden="true" id="use-case"></a><a href="#use-case" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Use case</h3>
<p>You have a folder called <code>imdir</code> that folder contains tens to millions of jpeg files, and another, <code>lab_path</code> that contains tens to millions of corresponding label images, also as jpeg files. Label images are 8-bit, and encode labels as unique integer pixel values.</p>
<p>For the code to work, the images and label images need to be jpegs. On linux with the <code>convert</code> function from imagemagick, convert folder of pngs into jpegs</p>
<pre><code class="hljs"><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> *.png
<span class="hljs-keyword">do</span>
convert <span class="hljs-variable">$file</span> $<span class="hljs-string">"<span class="hljs-variable">${file%.png}</span>.jpg"</span>
<span class="hljs-keyword">done</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="create-a-data-pre-processing-pipeline"></a><a href="#create-a-data-pre-processing-pipeline" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Create a data pre-processing pipeline</h3>
<p>Define a directory where you want to save your TFrecord files, called <code>tfrecord_dir</code></p>
<p>Get a list of the <code>images</code> in <code>imdir</code>, get the number of images <code>nb_images</code>, and compute the size of each shard and the number of shards</p>
<pre><code class="hljs">images = <span class="hljs-keyword">tf</span>.io.gfile.<span class="hljs-built_in">glob</span>(imdir+os.sep+<span class="hljs-string">'*.jpg'</span>)

nb_images=<span class="hljs-built_in">len</span>(<span class="hljs-keyword">tf</span>.io.gfile.<span class="hljs-built_in">glob</span>(imdir+os.sep+<span class="hljs-string">'*.jpg'</span>))

SHARDS = <span class="hljs-keyword">int</span>(nb_images / ims_per_shard) + (<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> nb_images % ims_per_shard != <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)

shared_size = <span class="hljs-keyword">int</span>(np.<span class="hljs-built_in">ceil</span>(<span class="hljs-number">1.0</span> * nb_images / SHARDS))s, <span class="hljs-string">'filename'</span>)
</code></pre>
<p>Next, define a pre-processing workflow</p>
<pre><code class="hljs"><span class="hljs-attr">dataset</span> = tf.data.Dataset.list_files(imdir+os.sep+<span class="hljs-string">'*.jpg'</span>, seed=<span class="hljs-number">10000</span>) <span class="hljs-comment"># This also shuffles the images</span>
<span class="hljs-attr">dataset</span> = dataset.map(read_image_and_label)
<span class="hljs-attr">dataset</span> = dataset.map(resize_and_crop_image, num_parallel_calls=AUTO)
<span class="hljs-attr">dataset</span> = dataset.map(recompress_image, num_parallel_calls=AUTO)
<span class="hljs-attr">dataset</span> = dataset.batch(shared_size)
</code></pre>
<p>Where the following function reads an image from file, and finds the corresponding label image and reads that in too (this example from the OBX dataset)</p>
<pre><code class="hljs">#-----------------------------------
def read_image_and_label(img_path):
    <span class="hljs-string">""</span><span class="hljs-comment">"</span>
    <span class="hljs-string">"read_image_and_label(img_path)"</span>
    This <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">reads</span> <span class="hljs-title">an</span> <span class="hljs-title">image</span> <span class="hljs-title">and</span> <span class="hljs-title">label</span> <span class="hljs-title">and</span> <span class="hljs-title">decodes</span> <span class="hljs-title">both</span> <span class="hljs-title">jpegs</span></span>
    into bytestring arrays.
    This works by parsing out the label image filename from its image pair
    Thre are different rules <span class="hljs-keyword">for</span> non-augmented versus augmented imagery
    INPUTS:
        * img_path [tensor <span class="hljs-built_in">string</span>]
    OPTIONAL INPUTS: None
    GLOBAL INPUTS: None
    OUTPUTS:
        * image [bytestring]
        * label [bytestring]
    <span class="hljs-string">""</span><span class="hljs-comment">"</span>
    bits = <span class="hljs-keyword">tf</span>.io.read_file(img_path)
    image = <span class="hljs-keyword">tf</span>.image.decode_jpeg(bits)

    # have <span class="hljs-keyword">to</span> use this <span class="hljs-keyword">tf</span>.strings.regex_replace utility because img_path <span class="hljs-keyword">is</span> <span class="hljs-keyword">a</span> Tensor object
    lab_path = <span class="hljs-keyword">tf</span>.strings.regex_replace(img_path, <span class="hljs-string">"images"</span>, <span class="hljs-string">"labels"</span>)
    lab_path = <span class="hljs-keyword">tf</span>.strings.regex_replace(lab_path, <span class="hljs-string">".jpg"</span>, <span class="hljs-string">"_deep_whitewater_shallow_no_water_label.jpg"</span>)
    lab_path = <span class="hljs-keyword">tf</span>.strings.regex_replace(lab_path, <span class="hljs-string">"augimage"</span>, <span class="hljs-string">"auglabel"</span>)
    bits = <span class="hljs-keyword">tf</span>.io.read_file(lab_path)
    label = <span class="hljs-keyword">tf</span>.image.decode_jpeg(bits)

    <span class="hljs-keyword">return</span> image, label
</code></pre>
<p>The following function crops and image and label pair to square and resizes to a <code>TARGET_SIZE</code></p>
<pre><code class="hljs">#-----------------------------------
def resize_and_crop_image(image, label):
    <span class="hljs-string">""</span><span class="hljs-comment">"</span>
    <span class="hljs-string">"resize_and_crop_image"</span>
    This <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">crops</span> <span class="hljs-title">to</span> <span class="hljs-title">square</span> <span class="hljs-title">and</span> <span class="hljs-title">resizes</span> <span class="hljs-title">an</span> <span class="hljs-title">image</span> <span class="hljs-title">and</span> <span class="hljs-title">label</span></span>
    INPUTS:
        * image [tensor array]
        * label [tensor array]
    OPTIONAL INPUTS: None
    GLOBAL INPUTS: TARGET_SIZE
    OUTPUTS:
        * image [tensor array]
        * label [tensor array]
    <span class="hljs-string">""</span><span class="hljs-comment">"</span>
    <span class="hljs-keyword">w</span> = <span class="hljs-keyword">tf</span>.shape(image)[<span class="hljs-number">0</span>]
    h = <span class="hljs-keyword">tf</span>.shape(image)[<span class="hljs-number">1</span>]
    tw = TARGET_SIZE
    <span class="hljs-keyword">th</span> = TARGET_SIZE
    resize_crit = (<span class="hljs-keyword">w</span> * <span class="hljs-keyword">th</span>) / (h * tw)
    image = <span class="hljs-keyword">tf</span>.cond(resize_crit &lt; <span class="hljs-number">1</span>,
                  lambd<span class="hljs-variable">a:</span> <span class="hljs-keyword">tf</span>.image.<span class="hljs-keyword">resize</span>(image, [<span class="hljs-keyword">w</span>*tw/<span class="hljs-keyword">w</span>, h*tw/<span class="hljs-keyword">w</span>]), # <span class="hljs-keyword">if</span> true
                  lambd<span class="hljs-variable">a:</span> <span class="hljs-keyword">tf</span>.image.<span class="hljs-keyword">resize</span>(image, [<span class="hljs-keyword">w</span>*<span class="hljs-keyword">th</span>/h, h*<span class="hljs-keyword">th</span>/h])  # <span class="hljs-keyword">if</span> false
                 )
    nw = <span class="hljs-keyword">tf</span>.shape(image)[<span class="hljs-number">0</span>]
    nh = <span class="hljs-keyword">tf</span>.shape(image)[<span class="hljs-number">1</span>]
    image = <span class="hljs-keyword">tf</span>.image.crop_to_bounding_box(image, (nw - tw) // <span class="hljs-number">2</span>, (nh - <span class="hljs-keyword">th</span>) // <span class="hljs-number">2</span>, tw, <span class="hljs-keyword">th</span>)

    label = <span class="hljs-keyword">tf</span>.cond(resize_crit &lt; <span class="hljs-number">1</span>,
                  lambd<span class="hljs-variable">a:</span> <span class="hljs-keyword">tf</span>.image.<span class="hljs-keyword">resize</span>(label, [<span class="hljs-keyword">w</span>*tw/<span class="hljs-keyword">w</span>, h*tw/<span class="hljs-keyword">w</span>]), # <span class="hljs-keyword">if</span> true
                  lambd<span class="hljs-variable">a:</span> <span class="hljs-keyword">tf</span>.image.<span class="hljs-keyword">resize</span>(label, [<span class="hljs-keyword">w</span>*<span class="hljs-keyword">th</span>/h, h*<span class="hljs-keyword">th</span>/h])  # <span class="hljs-keyword">if</span> false
                 )
    label = <span class="hljs-keyword">tf</span>.image.crop_to_bounding_box(label, (nw - tw) // <span class="hljs-number">2</span>, (nh - <span class="hljs-keyword">th</span>) // <span class="hljs-number">2</span>, tw, <span class="hljs-keyword">th</span>)

    <span class="hljs-keyword">return</span> image, label
</code></pre>
<p>This function takes images and labels as byte strings and recodes as a 8bit jpeg</p>
<pre><code class="hljs">#-----------------------------------
def recompress_image(image, <span class="hljs-keyword">label</span>):
    <span class="hljs-string">""</span>"
    <span class="hljs-string">"recompress_image"</span>
    This function takes <span class="hljs-keyword">an</span> image and <span class="hljs-keyword">label</span> encoded <span class="hljs-keyword">as</span> a byte string
    and recodes <span class="hljs-keyword">as</span> <span class="hljs-keyword">an</span> 8-bit jpeg
    INPUTS:
<span class="hljs-comment">        * image [tensor array]</span>
<span class="hljs-comment">        * label [tensor array]</span>
    OPTIONAL INPUTS: None
    <span class="hljs-keyword">GLOBAL</span> INPUTS: None
    OUTPUTS:
<span class="hljs-comment">        * image [tensor array]</span>
<span class="hljs-comment">        * label [tensor array]</span>
    <span class="hljs-string">""</span>"
    image = tf.cast(image, tf.uint8)
    image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)

    <span class="hljs-keyword">label</span> = tf.cast(<span class="hljs-keyword">label</span>, tf.uint8)
    <span class="hljs-keyword">label</span> = tf.image.encode_jpeg(<span class="hljs-keyword">label</span>, optimize_size=True, chroma_downsampling=False)
    <span class="hljs-keyword">return</span> image, <span class="hljs-keyword">label</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="write-tfrecord-shards-to-disk"></a><a href="#write-tfrecord-shards-to-disk" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Write TFrecord shards to disk</h3>
<p>Finally, write the dataset to tfrecord format files for 'analysis ready data' that is highly compressed and easy to share</p>
<pre><code class="hljs">for shard, (image, <span class="hljs-meta">label</span>) <span class="hljs-meta">in</span> enumerate(dataset):
  shard_size = image.numpy().shape[0]
  <span class="hljs-meta">filename</span> = tfrecord_dir+os.sep+<span class="hljs-string">"obx"</span> + <span class="hljs-string">"{:02d}-{}.tfrec"</span>.<span class="hljs-meta">format</span>(shard, shard_size)

  with tf.io.TFRecordWriter(<span class="hljs-meta">filename</span>) <span class="hljs-meta">as</span> out_file:
    for i <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>shard_size):
      example = to_seg_tfrecord(image.numpy()[i],<span class="hljs-meta">label</span>.numpy()[i])
      out_file.write(example.SerializeToString())
    p<span class="hljs-meta">rint(</span><span class="hljs-string">"Wrote file {} containing {} records"</span>.<span class="hljs-meta">format</span>(<span class="hljs-meta">filename</span>, shard_size))
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="image-augmentation"></a><a href="#image-augmentation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image augmentation</h3>
<p>Do you need to augment your imagery (create transformations of the image and label pairs and write them to disk)?</p>
<p>Define image dimensions</p>
<pre><code class="hljs"><span class="hljs-attr">NY</span> = <span class="hljs-number">7360</span>
<span class="hljs-attr">NX</span> = <span class="hljs-number">4912</span>
</code></pre>
<p>Define two <code>ImageDataGenerator</code> instances with the same arguments, one for images and the other for labels (masks)</p>
<pre><code class="hljs">data_gen_args = dict(<span class="hljs-attribute">featurewise_center</span>=<span class="hljs-literal">False</span>,
                     <span class="hljs-attribute">featurewise_std_normalization</span>=<span class="hljs-literal">False</span>,
                     <span class="hljs-attribute">rotation_range</span>=5,
                     <span class="hljs-attribute">width_shift_range</span>=0.1,
                     <span class="hljs-attribute">height_shift_range</span>=0.1,
                     <span class="hljs-attribute">zoom_range</span>=0.2)
image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(*<span class="hljs-number">*da</span>ta_gen_args)
mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(*<span class="hljs-number">*da</span>ta_gen_args)
</code></pre>
<p>You likely can't read all your images into memory, so you'll have to do this in batches. The following loop will grab a new random batch of images, apply the augmentation generator to the images to create alternate versions, then writes those alternate versions of images and labels to disk</p>
<pre><code class="hljs"><span class="hljs-attribute">i</span>=1
<span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> range(14):

    #<span class="hljs-builtin-name">set</span> a different seed each time <span class="hljs-keyword">to</span> <span class="hljs-builtin-name">get</span> a new batch of ten
    seed = int(np.random.randint(0,100,<span class="hljs-attribute">size</span>=1))
    img_generator = image_datagen.flow_from_directory(
            imdir,
            target_size=(NX, NY),
            <span class="hljs-attribute">batch_size</span>=10,
            <span class="hljs-attribute">class_mode</span>=None, <span class="hljs-attribute">seed</span>=seed, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)

    #the seed must be the same as <span class="hljs-keyword">for</span> the training <span class="hljs-builtin-name">set</span> <span class="hljs-keyword">to</span> <span class="hljs-builtin-name">get</span> the same images
    mask_generator = mask_datagen.flow_from_directory(
            lab_path,
            target_size=(NX, NY),
            <span class="hljs-attribute">batch_size</span>=10,
            <span class="hljs-attribute">class_mode</span>=None, <span class="hljs-attribute">seed</span>=seed, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)

    #The following merges the two generators (<span class="hljs-keyword">and</span> their flows) together:
    train_generator = (pair <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> zip(img_generator, mask_generator))

    #grab a batch of 10 images <span class="hljs-keyword">and</span> label images
    x, y = next(train_generator)

    # write them <span class="hljs-keyword">to</span> file <span class="hljs-keyword">and</span> increment the counter
    <span class="hljs-keyword">for</span> im,lab <span class="hljs-keyword">in</span> zip(x,y):
        imwrite(imdir+os.sep+<span class="hljs-string">'augimage_000'</span>+str(i)+<span class="hljs-string">'.jpg'</span>, im)
        imwrite(lab_path+os.sep+<span class="hljs-string">'auglabel_000'</span>+str(i)+<span class="hljs-string">'_deep_whitewater_shallow_no_water_label.jpg'</span>, lab)
        i += 1

    #save memory
    del x, y, im, lab
    #<span class="hljs-builtin-name">get</span> a new batch
</code></pre>
</span></div></div><div class="blogSocialSection"></div></div><div class="blog-recent"><a class="button" href="/MLMONDAYS/blog/">Recent Posts</a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/MLMONDAYS/" class="nav-home"><img src="/MLMONDAYS/img/favicon.ico" alt="&quot;ML Mondays&quot;" width="66" height="58"/></a><div><h5>Internal links</h5><a href="/MLMONDAYS/docs/en/doc1.html">Docs</a><a href="/MLMONDAYS/docs/en/doc2.html">Data</a><a href="/MLMONDAYS/docs/en/doc3.html">Help</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://www.usgs.gov/centers/cdi" target="_blank" rel="noreferrer noopener">USGS Community for Data Integration (CDI)</a><a href="https://www.usgs.gov/centers/pcmsc/science/remote-sensing-coastal-change?qt-science_center_objects=0#qt-science_center_objects" target="_blank" rel="noreferrer noopener">USGS Remote Sensing Coastal Change Project</a><a href="https://www.danielbuscombe.com" target="_blank" rel="noreferrer noopener">www.danielbuscombe.com</a></div><div><h5>More</h5><a href="/MLMONDAYS/blog">Blog</a><a href="https://github.com/dbuscombe-usgs/DL-CDI2020">GitHub</a><a class="github-button" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a><div class="social"><a href="https://twitter.com/magic_walnut" class="twitter-follow-button">Follow @magic_walnut</a></div></div></section><a href="https://mardascience.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/MLMONDAYS/img/dash-logo-new.png" alt="Marda Science" width="170" height="45"/></a><section class="copyright">Copyright © 2020 Marda Science, LLC</section></footer></div><script>window.twttr=(function(d,s, id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return t;js=d.createElement(s);js.id=id;js.src='https://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js, fjs);t._e = [];t.ready = function(f) {t._e.push(f);};return t;}(document, 'script', 'twitter-wjs'));</script></body></html>