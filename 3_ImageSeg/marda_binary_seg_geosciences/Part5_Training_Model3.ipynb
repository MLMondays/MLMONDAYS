{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part5_Training_Model3.ipynb","provenance":[{"file_id":"1jS4dlniRgeAQwxmNej-gTA7JN_v85DcI","timestamp":1589686974085},{"file_id":"1vTn59E-BpCq0J2N60G1N9bfit3qKY50i","timestamp":1586576184811}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNRSuu+3HjBz5KWsI/o/jaV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BparhBMOqPX2","colab_type":"text"},"source":["# Advanced Binary Image Segmentation for the Geo- and Eco-sciences, using Deep Learning\n","\n","## Case Study: Detecting Intertidal Reefs\n","\n","#### Daniel Buscombe, MARDA Science\n","\n","![](https://mardascience.com/wp-content/uploads/2019/06/cropped-MardaScience_logo-5.png)"]},{"cell_type":"markdown","metadata":{"id":"GZQPghmJrbV6","colab_type":"text"},"source":["Before you do anything, go to `File > Save copy in Drive` so you can keep and work on your own copy\n","\n","## Part 5: Train a oyster reef masker using a custom learning rate scheduler\n","\n","This jupyter notebook running on Google Colab is part of the \"Advanced Binary Image Segmentation for the Geo- and Eco-sciences, using Deep Learning\" course. The main course website can be accessed [here](https://mardascience.gitlab.io/binary_image_segmentation_for_geosciences/#/)\n","\n","Then we will construct, train and evaluate the model. In the [oysterNet paper](https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.134), the authors used a bigger, more sophisticated model for `instance segmentation`, that is, semantic segmentation that is aware of all the different `instances` of the class (i.e. each individual piece of reef). The model they use is called `Mask RCNN`, the implementation of which is [here](https://github.com/matterport/Mask_RCNN). That is a large and very complicated model that is hard to experiment with. The research behind the [oysterNet paper](https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.134) is state-of-the-art.\n","\n","Here, we use a simpler model with fewer parameters (namely, a residual UNet) and acheive acceptable results for a semantic segmentation (predicting the masks of where the reefs are, rather than by individual instances). The UNet is the same we used in a [previous set of tutorials](https://mardascience.gitlab.io/deep_learning_landscape_classification/#/) and is relatively simple to adapt and play with to demonstrate a few principles.\n","\n","**In this tutorial, we'll adapt our training strategies in search of a more satisfactory result. This may or may not be directly transferable with the same fidelity to your own dataset, but this is a good trick to learn and understand that might help for your data modelling purposes. This time we use a cyclical learning rate scheduler**\n","\n","According to [this](https://arxiv.org/abs/1506.01186) and [this](https://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/), there are a few reasons why we would want to trial this strategy\n","* a low learning rate may not be sufficient to break out of the non-optimal areas of the loss landscape and descend into areas of the loss landscape with lower loss.\n","* our model and optimizer may be very sensitive to our initial learning rate choice\n","\n","\n","This is designed to demonstrate a problem-solving strategy, and also a principle that often applies to natural imagery:\n","\n","> It's not just the model you choose, it's how you train it that counts\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LBlz78KvrbZK","colab_type":"text"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"S6GxV5d5rb5M","colab_type":"code","colab":{}},"source":["import os #for accessing operating system utilities\n","from glob import glob #for finding files that match a certain string pattern\n","import matplotlib.pyplot as plt #for plotting\n","import numpy as np #for numerical operations\n","import random, string #for creating random strings\n","import tensorflow as tf #tensorflow\n","import json # for reading lable annotations in json format\n","import requests #for downloading files \n","from PIL import Image, ImageFilter #for reading and filtering imagery\n","import skimage.draw #for making masks (raster label images) from label annotations\n","from skimage.transform import resize #for resizing imagery\n","from psutil import virtual_memory #for interrogating our filesystem and RAM specifications\n","from imageio import imwrite"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMAuPUQ9_tlc","colab_type":"code","colab":{}},"source":["from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from random import shuffle\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n","from tensorflow.keras.layers import Concatenate, Conv2DTranspose, Flatten, Activation, Add\n","from tensorflow.keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dxvEIv-xVN_k"},"source":["### Prepare the data"]},{"cell_type":"markdown","metadata":{"id":"kcmGOhVPLUSh","colab_type":"text"},"source":["#### Download the  imagery\n"]},{"cell_type":"markdown","metadata":{"id":"hkoi8XeN8ifp","colab_type":"text"},"source":["For the remainder of the tutorials, we'll be using this version of the data, consisting of imagery and image labels, with an augmented training set consisting of double the original number of imagery, half of which have been augmented with random flips, zoms and rotations"]},{"cell_type":"code","metadata":{"id":"VYs1Wf3Ce_Pb","colab_type":"code","colab":{}},"source":["# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n","\n","def download_file_from_google_drive(id, destination):\n","    URL = \"https://docs.google.com/uc?export=download\"\n","\n","    session = requests.Session()\n","\n","    response = session.get(URL, params = { 'id' : id }, stream = True)\n","    token = get_confirm_token(response)\n","\n","    if token:\n","        params = { 'id' : id, 'confirm' : token }\n","        response = session.get(URL, params = params, stream = True)\n","\n","    save_response_content(response, destination)    \n","\n","def get_confirm_token(response):\n","    for key, value in response.cookies.items():\n","        if key.startswith('download_warning'):\n","            return value\n","\n","    return None\n","\n","def save_response_content(response, destination):\n","    \"\"\"\n","    response = filename for input\n","    destination = filename for output\n","    \"\"\"    \n","    CHUNK_SIZE = 32768\n","\n","    with open(destination, \"wb\") as f:\n","        for chunk in response.iter_content(CHUNK_SIZE):\n","            if chunk: # filter out keep-alive new chunks\n","                f.write(chunk)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-3XRHzZraV7","colab_type":"code","colab":{}},"source":["file_id = '19RgkzaD9w-rvAF9uBpqMONnwF0lJVPh3'\n","destination = 'train_images.tar.gz'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XlKU4QNrmY6","colab_type":"code","colab":{}},"source":["!tar -xf train_images.tar.gz > tmp.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6r1O0TTe0J-","colab_type":"code","colab":{}},"source":["file_id = '1gjWGXO7mtBhJuSOqrG6B1inzLF8TfTSX'\n","destination = 'val_images.tar.gz'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LyxVjRxE9P7","colab_type":"code","colab":{}},"source":["!tar -xf val_images.tar.gz > tmp.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQm4jizqrm62","colab_type":"code","colab":{}},"source":["file_id = '1x8HrgEStkBCdBmFNo1xa0x6LCVE2GE1g'\n","destination = 'train_labels.tar.gz'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxvguWMMFAWB","colab_type":"code","colab":{}},"source":["!tar -xf train_labels.tar.gz > tmp.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCeJ6_iEEhzx","colab_type":"code","colab":{}},"source":["file_id = '1v0kPgwZVQNrGAk0awJi31W83CYvHJbeX'\n","destination = 'val_labels.tar.gz'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bbp72OZwFGkk","colab_type":"code","colab":{}},"source":["!tar -xf val_labels.tar.gz > tmp.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Vryno6hFOwp","colab_type":"code","colab":{}},"source":["root = './content/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zwn2Cg29FWen"},"source":["Check to see how many images we now have to work with"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"7c4fb5da-4ca7-4a53-ee09-ccd0e9295239","executionInfo":{"status":"ok","timestamp":1590017687559,"user_tz":420,"elapsed":58753,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"id":"UFRC78IaFWe3","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["train_files = glob(root+\"1kx1k_dataset/train_images/data/*.png\")\n","val_files = glob(root+\"1kx1k_dataset/val_images/data/*.png\")\n","\n","print(\"# train files: %i\" % (len(train_files)))\n","print(\"# validation files: %i\" % (len(val_files)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["# train files: 1054\n","# validation files: 130\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t19wozDYNtrf","colab_type":"text"},"source":["### Setting up model training"]},{"cell_type":"markdown","metadata":{"id":"u9Unigzk4niP","colab_type":"text"},"source":["#### Custom batch generator"]},{"cell_type":"markdown","metadata":{"id":"-URhGi8YNw9M","colab_type":"text"},"source":["We are going to feed images to the network in batches. The batch size (number of images and associated labels) will be ..."]},{"cell_type":"code","metadata":{"id":"pObzrY8xwC5Y","colab_type":"code","colab":{}},"source":["batch_size = 6"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bLpnz8g7N5vx","colab_type":"text"},"source":["The next function is an image batch generator. A `generator` is a special type of python function that `yields` a set of data. In our case, it will yield a set of `batch_size` images and labels drawn randomly from the entire set of `files` provided\n","\n","It opens the file, reads it into a numpy array with correct dimensions checked, and then does the same for the label image. It scales the image by dividing by 255, do turn the 8-bit data scaled between 0 and 255 to data scaled between 0 and 1. The labels are flattened from 3D (RGB) to 2D (greyscale integers)"]},{"cell_type":"code","metadata":{"id":"xzbxS7WTpj_e","colab_type":"code","colab":{}},"source":["def image_batch_generator(files, sz, batch_size = 4):\n","\n","  while True: # this is here because it will be called repeatedly by the training function\n","\n","    #extract a random subset of files of length \"batch_size\"\n","    batch = np.random.choice(files, size = batch_size)\n","\n","    #variables for collecting batches of inputs (x) and outputs (y)\n","    batch_x = []\n","    batch_y = []\n","\n","    #cycle through each image in the batch\n","    for f in batch:\n","\n","        #preprocess the raw images\n","        raw = Image.open(f)\n","        raw = raw.resize(sz)\n","        raw = raw.filter(ImageFilter.UnsharpMask(radius=20, percent=100))\n","        raw = np.array(raw)\n","\n","        #check the number of channels because some of the images are RGBA or GRAY\n","        if len(raw.shape) == 2:\n","            raw = np.stack((raw,)*3, axis=-1)\n","\n","        else:\n","            raw = raw[:,:,0:3]\n","\n","        #get the image dimensions, find the min dimension, then square the image off\n","        nx, ny, nz = np.shape(raw)\n","        n = np.minimum(nx,ny)\n","        raw = raw[:n,:n,:]\n","\n","        raw[np.isnan(raw)] = 1e-5\n","        raw[np.isinf(raw)] = 1e-5\n","\n","        batch_x.append(raw)\n","\n","        #get the masks.\n","        maskfile = f.replace('_images','_labels').replace('.png','.jpg')\n","        mask = Image.open(maskfile)\n","        # the mask is 3-dimensional so get the max in each channel to flatten to 2D\n","        try:\n","           mask = np.max(np.array(mask.resize(sz)),axis=2)\n","        except:\n","           mask = np.array(mask.resize(sz))\n","\n","        # water pixels are always greater than 170\n","        mask = (mask>170).astype('int') ##170 = (2/3)*255\n","\n","        mask = mask[:n,:n]\n","\n","        mask[np.isnan(mask)] = 1e-5\n","        mask[np.isinf(mask)] = 1e-5\n","        batch_y.append(mask)\n","\n","    #preprocess a batch of images and masks\n","    batch_x = np.array(batch_x) #/255. #divide image by 255 to normalize\n","    batch_y = np.array(batch_y)\n","    batch_y = np.expand_dims(batch_y,1) #add singleton dimension to batch_y\n","\n","    yield (batch_x, batch_y) #yield both the image and the label together"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tp6asF7xPAYx","colab_type":"text"},"source":["We will specify input imagery of size `(512, 512, 3)`"]},{"cell_type":"code","metadata":{"id":"NCpNQZou34G-","colab_type":"code","colab":{}},"source":["sz = (512, 512)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_hkJRgPcRJuo","colab_type":"text"},"source":["#### Build the model"]},{"cell_type":"markdown","metadata":{"id":"jkkVKZ7Wc_Kj","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"T2ItAauaT3j0","colab_type":"code","colab":{}},"source":["def batchnorm_act(x):\n","    x = BatchNormalization()(x)\n","    return Activation(\"relu\")(x)\n","\n","def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    conv = batchnorm_act(x)\n","    return Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n","\n","def bottleneck_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n","    \n","    bottleneck = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n","    bottleneck = batchnorm_act(bottleneck)\n","    \n","    return Add()([conv, bottleneck])\n","\n","def res_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n","    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n","    \n","    bottleneck = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n","    bottleneck = batchnorm_act(bottleneck)\n","    \n","    return Add()([bottleneck, res])\n","\n","def upsamp_concat_block(x, xskip):\n","    u = UpSampling2D((2, 2))(x)\n","    return Concatenate()([u, xskip])\n","\n","def res_unet(sz, f):\n","    inputs = Input(sz)\n","    \n","    ## downsample  \n","    e1 = bottleneck_block(inputs, f); f = int(f*2)\n","    e2 = res_block(e1, f, strides=2); f = int(f*2)\n","    e3 = res_block(e2, f, strides=2); f = int(f*2)\n","    e4 = res_block(e3, f, strides=2); f = int(f*2)\n","    _ = res_block(e4, f, strides=2)\n","    \n","    ## bottleneck\n","    b0 = conv_block(_, f, strides=1)\n","    _ = conv_block(b0, f, strides=1)\n","    \n","    ## upsample\n","    _ = upsamp_concat_block(_, e4)\n","    _ = res_block(_, f); f = int(f/2)\n","    \n","    _ = upsamp_concat_block(_, e3)\n","    _ = res_block(_, f); f = int(f/2)\n","    \n","    _ = upsamp_concat_block(_, e2)\n","    _ = res_block(_, f); f = int(f/2)\n","    \n","    _ = upsamp_concat_block(_, e1)\n","    _ = res_block(_, f)\n","    \n","    ## classify\n","    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(_)\n","    \n","    #model creation \n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    return model\n","\t"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ucLYscX_-FPT","colab_type":"text"},"source":["This is a class imbalanced problem, with many more `non-reef` pixels compared to `reef` pixels (the target class)\n","\n","So, we will use (Sorensen-)Dice loss instead of the more common IoU score (Jaccard Index) which is more suitable for class balanced problems"]},{"cell_type":"code","metadata":{"id":"Bfr9DmM1U_tg","colab_type":"code","colab":{}},"source":["smooth = 1.\n","\n","def dice_coef(y_true, y_pred):\n","    y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32), [-1])\n","    y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32), [-1])\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lowoYtUf-GKm","colab_type":"text"},"source":["Next, we make and compile our model\n","\n","As we saw in lesson 1, model compilation is a necessary step, involving specifiying the 'optimizer' (we will use `rmsprop` but `adam` is also a good one to use, in my experience). The loss function is the Dice loss, and the metric we want to keep track of in the dice coefficient"]},{"cell_type":"code","metadata":{"id":"ikGheqaqG1am","colab_type":"code","colab":{}},"source":["model = res_unet(sz+(3,), batch_size)\n","model.compile(optimizer = 'adam', loss = dice_coef_loss, metrics = [dice_coef])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_RIoaaF_gbMY","colab_type":"text"},"source":["Let's take a look at how many parameters we have to optimize"]},{"cell_type":"code","metadata":{"id":"Ro7XZPenjLo8","colab_type":"code","outputId":"0e285e6c-50f9-46fb-8bc3-1d914fe8347e","executionInfo":{"status":"ok","timestamp":1590017697057,"user_tz":420,"elapsed":58307,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 512, 512, 6)  168         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 512, 512, 6)  24          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 512, 512, 6)  24          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 512, 512, 6)  0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 512, 512, 6)  24          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 512, 512, 6)  330         activation[0][0]                 \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 512, 512, 6)  0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 512, 512, 6)  0           conv2d_1[0][0]                   \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 512, 512, 6)  24          add[0][0]                        \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 512, 512, 6)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 256, 256, 12) 660         activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 256, 256, 12) 84          add[0][0]                        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 256, 256, 12) 48          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 256, 256, 12) 48          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 256, 256, 12) 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 256, 256, 12) 0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 256, 256, 12) 1308        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 256, 256, 12) 0           activation_4[0][0]               \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 256, 256, 12) 48          add_1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 256, 256, 12) 0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 128, 128, 24) 2616        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 128, 128, 24) 312         add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 128, 128, 24) 96          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 24) 96          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 128, 128, 24) 0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 24) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 24) 5208        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 128, 128, 24) 0           activation_7[0][0]               \n","                                                                 conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 128, 128, 24) 96          add_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 128, 128, 24) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 64, 64, 48)   10416       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 64, 64, 48)   1200        add_2[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 64, 64, 48)   192         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 64, 64, 48)   192         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 64, 64, 48)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 64, 64, 48)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 64, 64, 48)   20784       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 64, 64, 48)   0           activation_10[0][0]              \n","                                                                 conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 64, 64, 48)   192         add_3[0][0]                      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 64, 64, 48)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 96)   41568       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 32, 32, 96)   4704        add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 96)   384         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 96)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 96)   83040       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 32, 32, 96)   0           activation_13[0][0]              \n","                                                                 conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 32, 32, 96)   384         add_4[0][0]                      \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 32, 32, 96)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 96)   83040       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 32, 32, 96)   384         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 32, 32, 96)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 32, 32, 96)   83040       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 64, 64, 96)   0           conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 64, 64, 144)  0           up_sampling2d[0][0]              \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 64, 64, 144)  576         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 64, 64, 144)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 64, 64, 96)   124512      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 64, 64, 96)   13920       concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 64, 64, 96)   384         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 64, 64, 96)   384         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 64, 64, 96)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 64, 64, 96)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 64, 64, 96)   83040       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 64, 64, 96)   0           activation_18[0][0]              \n","                                                                 conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 96) 0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 128, 128, 120 0           up_sampling2d_1[0][0]            \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 128, 128, 120 480         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 128, 128, 120 0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 128, 128, 48) 51888       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 128, 128, 48) 5808        concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 128, 128, 48) 192         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 128, 128, 48) 192         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 128, 128, 48) 0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 128, 128, 48) 0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 128, 128, 48) 20784       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 128, 128, 48) 0           activation_21[0][0]              \n","                                                                 conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 48) 0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 256, 256, 60) 0           up_sampling2d_2[0][0]            \n","                                                                 add_1[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 256, 256, 60) 240         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 256, 256, 60) 0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 256, 256, 24) 12984       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 256, 256, 24) 1464        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 256, 256, 24) 96          conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 256, 256, 24) 96          conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 256, 256, 24) 0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 256, 256, 24) 0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 256, 256, 24) 5208        activation_23[0][0]              \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 256, 256, 24) 0           activation_24[0][0]              \n","                                                                 conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 24) 0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 512, 512, 30) 0           up_sampling2d_3[0][0]            \n","                                                                 add[0][0]                        \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 512, 512, 30) 120         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 512, 512, 30) 0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 512, 512, 12) 3252        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 512, 512, 12) 372         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 512, 512, 12) 48          conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 512, 512, 12) 48          conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 512, 512, 12) 0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 512, 512, 12) 0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 512, 512, 12) 1308        activation_26[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 512, 512, 12) 0           activation_27[0][0]              \n","                                                                 conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 512, 512, 1)  13          add_8[0][0]                      \n","==================================================================================================\n","Total params: 668,527\n","Trainable params: 665,791\n","Non-trainable params: 2,736\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FgQz6ywhjNrT","colab_type":"text"},"source":["We have over 600,000 trainable parameters. This is a lot, for any model, but tiny compared to the number of parameters in some deep learning models, with up to hundreds of millions of trainable parameters"]},{"cell_type":"markdown","metadata":{"id":"8UZCmUlmczaq","colab_type":"text"},"source":["### Train the model with a custom \"learning rate scheduler\""]},{"cell_type":"code","metadata":{"id":"gUne-hibLDFl","colab_type":"code","colab":{}},"source":["callbacks = tf.keras.callbacks\n","backend = tf.keras.backend\n","\n","\n","class PlotLearning(callbacks.Callback):\n","\n","    def on_train_begin(self, logs={}):\n","        self.i = 0\n","        self.x = []\n","        self.losses = []\n","        self.val_losses = []\n","        self.acc = []\n","        self.val_acc = []\n","        #self.fig = plt.figure()\n","        self.logs = []\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(logs)\n","        self.x.append(self.i)\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.acc.append(logs.get('dice_coef'))\n","        self.val_acc.append(logs.get('val_dice_coef'))\n","        self.i += 1\n","        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'dice_coef=',logs.get('dice_coef'),'val_dice_coef=',logs.get('val_dice_coef'))\n","\n","        #choose a random test image and preprocess\n","        f = np.random.choice(val_files)\n","\n","        raw = np.array(Image.open(f).resize(sz))\n","\n","        #predict the mask\n","        pred = 255*model.predict(np.expand_dims(raw, 0)).squeeze()\n","        print(np.max(pred))\n","\n","        #mask post-processing\n","        msk  = (pred>170).astype('int') \n","\n","        msk = np.stack((msk,)*3, axis=-1)\n","\n","        #show the mask and the segmented image\n","        combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n","        plt.axis('off')\n","        plt.imshow(combined)\n","        plt.show()\n","        #plt.savefig(str(self.i)+'.png', dpi=100, bbox_inches='tight')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tjH9Q--hcxmH","colab_type":"text"},"source":["In Part 3 we used callback functions that adaptively change the pace of training (using an adaptive learning rate), called [\"reduce loss on plateau\"](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau)\n","\n","This time we'll control precisely the learning rate scheduler to invoke a function that describes the learning rate as a function of training epoch\n","\n","To do so requires a new class that will feed the model the correct learning rate based on the epoch it is current training on\n","\n"]},{"cell_type":"code","metadata":{"id":"NooVSxDGfn5N","colab_type":"code","colab":{}},"source":["class LearningRateScheduler(callbacks.Callback):\n","    def __init__(self,\n","                 schedule,\n","                 learning_rate=None,\n","                 steps_per_epoch=None,\n","                 verbose=0):\n","        super(LearningRateScheduler, self).__init__()\n","        self.learning_rate = learning_rate\n","        self.schedule = schedule\n","        self.verbose = verbose\n","        self.warmup_epochs = 0 \n","        self.warmup_steps = 0 \n","        self.global_batch = 0\n","\n","    def on_train_batch_begin(self, batch, logs=None):\n","        self.global_batch += 1\n","        if self.global_batch < self.warmup_steps:\n","            if not hasattr(self.model.optimizer, 'lr'):\n","                raise ValueError('Optimizer must have a \"lr\" attribute.')\n","            lr = self.learning_rate * self.global_batch / self.warmup_steps\n","            backend.set_value(self.model.optimizer.lr, lr)\n","            if self.verbose > 0:\n","                print('\\nBatch %05d: LearningRateScheduler warming up learning '\n","                      'rate to %s.' % (self.global_batch, lr))\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        if not hasattr(self.model.optimizer, 'lr'):\n","            raise ValueError('Optimizer must have a \"lr\" attribute.')\n","        lr = float(backend.get_value(self.model.optimizer.lr))\n","\n","        if epoch >= self.warmup_epochs:\n","            try:  # new API\n","                lr = self.schedule(epoch - self.warmup_epochs, lr)\n","            except TypeError:  # old API\n","                lr = self.schedule(epoch - self.warmup_epochs)\n","            if not isinstance(lr, (float, np.float32, np.float64)):\n","                raise ValueError('The output of the \"schedule\" function '\n","                                 'should be float.')\n","            backend.set_value(self.model.optimizer.lr, lr)\n","\n","            if self.verbose > 0:\n","                print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n","                      'rate to %s.' % (epoch + 1, lr))\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        logs['lr'] = backend.get_value(self.model.optimizer.lr)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ef7MCjSZcNWm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qlm1R1oMcNi2","colab_type":"text"},"source":["This is our cosine function implementation for a 'cyclical' learning rate between two specified bounds, `min_lr` (minimum learning rate) and `max_lr` (maximum learning rate)"]},{"cell_type":"code","metadata":{"id":"cA6FYKETgJqV","colab_type":"code","colab":{}},"source":["def cosine_ratedecay(max_epochs, max_lr, min_lr=1e-6): \n","    \"\"\"\n","    cosine scheduler.\n","    :param max_epochs: max epochs\n","    :param max_lr: max lr\n","    :param min_lr: min lr\n","    :return: current lr\n","    \"\"\"\n","    max_epochs = max_epochs ##- 5 if warmup else max_epochs\n","\n","    def ratedecay(epoch):\n","        lrate = min_lr + (max_lr - min_lr) * (\n","                1 + np.cos(np.pi*2 * epoch / max_epochs)) / 2\n","\n","        return lrate\n","\n","    return ratedecay"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gCZikifIcZx1","colab_type":"text"},"source":["We now have two new hyperparameters we didn't have before"]},{"cell_type":"code","metadata":{"id":"1HmanEbyDcJb","colab_type":"code","colab":{}},"source":["# maximum learning rate (lambda)\n","max_lr = 1e-4\n","\n","max_epochs = 200"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Tj8TfH7hrr_","colab_type":"text"},"source":["The \"two bites at the cherry\" learning rate scheduler. The intuition behind this is that the model searches progressively finer portions of the loss parameter space, up until about epoch 70, then the function increases again, using larger learning rates to explore other 'valleys' in the loss landscape. \n","\n","I informally call it the 'two bites at the cherry' function because it facilitates the following situation: the optimal low in the loss landscape was not effectively found by the first loop of progressively lower learning rates. Giving the model a 'second bite' allows it to find a new low by adjusting learning rates to be coarse, so it can hop to different areas of the loss landscape more effectively "]},{"cell_type":"code","metadata":{"id":"vI_ewXkchKEF","colab_type":"code","outputId":"f24b6dbe-8335-4690-a05f-467b5e8a931a","executionInfo":{"status":"ok","timestamp":1590017975002,"user_tz":420,"elapsed":977,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["min_lr = 1e-6\n","def ratedecay(epoch):\n","    lrate = min_lr + (max_lr - min_lr) * (\n","            1 + np.cos(np.pi*3 * epoch / max_epochs)) / 2\n","\n","    return lrate\n","\n","plt.plot(ratedecay(np.arange(max_epochs)))    "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f71b22000b8>]"]},"metadata":{"tags":[]},"execution_count":26},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"BuMn9p_SpFKK","colab_type":"text"},"source":["Now we have defined all these hyperparameters (parameters that we chose, not automatically determined by the model), we can make a function that builds all the various callbacks together into a list, which can then be passed to the model training (`.fit()` function)"]},{"cell_type":"code","metadata":{"id":"5f_oabeno1kX","colab_type":"code","colab":{}},"source":["def build_callbacks(filepath, lr_ratedecay, lr, steps_per_epoch):\n","\n","    # set checkpoint file\n","    model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss',\n","                                   verbose=0, save_best_only=True, mode='min',\n","                                   save_weights_only = True)\n","\n","    # learning rate scheduler setting\n","    learning_rate_scheduler = LearningRateScheduler(lr_ratedecay, lr, steps_per_epoch,\n","                                                verbose=1)\n","\n","    callbacks = [model_checkpoint, learning_rate_scheduler, PlotLearning()]\n","\n","    return callbacks"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dsNnFFmTcyFD","colab_type":"text"},"source":["Next, set up a name for the `.h5` file that will be used to store model weights.\n","\n","Finally, we train the model by calling the `.fit()` command and providing all the generators and hyperparameters defined in the callbacks\n","\n","The number of training and validation steps is simply the number of respective files divided by the batch size"]},{"cell_type":"code","metadata":{"id":"ZExSJHTacJR8","colab_type":"code","outputId":"6638d0cf-411a-423f-8024-cc1a6b52803a","executionInfo":{"status":"ok","timestamp":1590017979634,"user_tz":420,"elapsed":916,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["filepath = 'reefs_weights_uresnet'+str(batch_size)+'_'+str(max_epochs)+'epochs_cosine_lrscheduler.h5'\n","\n","train_generator = image_batch_generator(train_files, sz, batch_size = batch_size)\n","val_generator  = image_batch_generator(val_files, sz, batch_size = batch_size)\n","train_steps = len(train_files) //batch_size\n","val_steps = len(val_files) //batch_size\n","steps_per_epoch = len(train_files) // batch_size\n","\n","print(train_steps)\n","print(val_steps)\n","print(steps_per_epoch)\n","\n","lr_ratedecay = cosine_ratedecay(max_epochs,max_lr)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["175\n","21\n","175\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IzMD33PpnMSP","colab_type":"text"},"source":["If you'd rather not wait the 3-6 hours it might take to train the model you should leave the following cell uncommented "]},{"cell_type":"code","metadata":{"id":"J7EcdN8RnOdv","colab_type":"code","colab":{}},"source":["file_id = '1LyjyOxuzYzmWrwh6kxPVDZZWEzZGehNq'\n","destination = 'weights_part5.h5'\n","download_file_from_google_drive(file_id, destination)\n","model.load_weights(destination)\n","max_epochs = 5 #just use 5 epochs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjYIPrCorZqL","colab_type":"text"},"source":["If you wish to train the model your own model, uncomment the cells below"]},{"cell_type":"code","metadata":{"id":"l4WCkNuZnNHd","colab_type":"code","colab":{}},"source":["# hist = model.fit(train_generator,\n","#                 epochs = max_epochs, steps_per_epoch = train_steps,\n","#                 validation_data = val_generator, validation_steps = val_steps,\n","#                 callbacks = build_callbacks(filepath,lr_ratedecay, max_lr, steps_per_epoch))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r25bK-MsrzNT","colab_type":"text"},"source":["#### Plot the training history"]},{"cell_type":"markdown","metadata":{"id":"ESXA7Lvmzggp","colab_type":"text"},"source":["In the above, we gave an output variable to the `.fit()` command. This contains the training histories. That is, losses and metrics as a function of epoch. You can access the variables in the dictionary like so"]},{"cell_type":"code","metadata":{"id":"IkS9ZmxWz7Ml","colab_type":"code","outputId":"16207904-7175-4135-f4ff-903364a475b6","executionInfo":{"status":"ok","timestamp":1590018669350,"user_tz":420,"elapsed":917,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# hist.history.keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'dice_coef', 'val_loss', 'val_dice_coef', 'lr'])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"8vawx9Zt03oY","colab_type":"text"},"source":["Let's make a plot of the histories of both train and validation losses and dice coefficients, and also the history of the learning rate"]},{"cell_type":"code","metadata":{"id":"DgVgvTMu-9Bw","colab_type":"code","colab":{}},"source":["# plt.figure(figsize=(20,10))\n","# plt.subplot(131)\n","# plt.plot(hist.history['dice_coef'], 'b', label='train Dice coefficient')\n","# plt.plot(hist.history['val_dice_coef'], 'k', label='validation Dice coefficient')\n","# plt.xlabel('Epoch number'); plt.ylabel('Dice coefficent')\n","# plt.legend()\n","\n","# plt.subplot(132)\n","# plt.plot(hist.history['loss'], 'b', label='train loss')\n","# plt.plot(hist.history['val_loss'], 'k', label='validation loss')\n","# plt.xlabel('Epoch number'); plt.ylabel('Loss')\n","# plt.legend()\n","\n","# plt.subplot(133)\n","# plt.plot(hist.history['lr'], 'g')\n","# plt.xlabel('Epoch number'); plt.ylabel('Learning rate')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pjm-wLWEruX3","colab_type":"text"},"source":["### Test the model"]},{"cell_type":"markdown","metadata":{"id":"dLREeeQ9th6J","colab_type":"text"},"source":["Get the test set of files and untar like we did the other sets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hng70579rsYg","colab":{}},"source":["file_id = '1lL6cbUNhwAQsDl4P4LIYiOMOwKxrhq-c'\n","destination = 'test_images.tar.gz'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P0pimK1SrsZQ","colab":{}},"source":["!tar -xf test_images.tar.gz > tmp.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AVfQmZvLrsZj","colab":{}},"source":["file_id = '1GVZgjzuVatp-OjU5s5DJOgAteUvN1yDC'\n","destination = 'test_labels.tar.gz'\n","download_file_from_google_drive(file_id, destination)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eZr3b4uTrsZy","colab":{}},"source":["!tar -xf test_labels.tar.gz > tmp.txt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cF4GYcA6tmTy","colab_type":"text"},"source":["Get a test generator"]},{"cell_type":"code","metadata":{"id":"G-wqGB4yqYzZ","colab_type":"code","outputId":"7cd85658-d335-4c2f-a2b3-803c218206fd","executionInfo":{"status":"ok","timestamp":1590018698292,"user_tz":420,"elapsed":10802,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_files = glob(root+\"1kx1k_dataset/test_images/*.png\")\n","\n","test_generator = image_batch_generator(test_files, sz, batch_size = batch_size)\n","\n","print(\"# test files: %i\" % (len(test_files)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["# test files: 163\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IYMqIAJdrTHe","colab_type":"text"},"source":["Use the `.evaluate()` function of the model to get average Dice scores and losses for the test set\n","\n"]},{"cell_type":"code","metadata":{"id":"PxYHG5yRrP3G","colab_type":"code","outputId":"3e7f9a86-79f1-4dae-bfe1-5c218be15748","executionInfo":{"status":"ok","timestamp":1590018716864,"user_tz":420,"elapsed":15214,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# some other training parameters\n","steps = len(test_files) // batch_size\n","\n","# testing\n","scores = model.evaluate(test_generator, steps=steps) \n","\n","print('loss={loss:0.4f}, Mean Dice={dice_coef:0.4f}'.format(loss=scores[0], dice_coef=scores[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["27/27 [==============================] - 13s 496ms/step - loss: 0.1998 - dice_coef: 0.8002\n","loss=0.1998, Mean Dice=0.8002\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P2JcQX4QuBc3","colab_type":"text"},"source":["In the [oysterNet paper](https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1002/rse2.134), the authors reeport a best precision of 0.771 and recall of 0.772. The Dice score is mathematically equivalent to the F1 score, the harmonic mean of precision and recall, or 77%\n","\n","In Part 4, we acheived an average dice score of ~72% using a Dice loss function and adaptive learning rates that were contingent on validation loss\n","\n","This time, with a cyclical learning rate, we acheive ~80% - approximately the same as the original paper (actually, a little higher!)"]}]}