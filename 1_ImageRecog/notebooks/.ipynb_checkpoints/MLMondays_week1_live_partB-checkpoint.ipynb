{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgXhgHivzYgi"
   },
   "source": [
    "![](https://dbuscombe-usgs.github.io/MLMONDAYS/img/favicon.ico)\n",
    "\n",
    "# ML-Mondays. Week 1: Supervised Image Recognition\n",
    "\n",
    "\n",
    "See the [course website](https://dbuscombe-usgs.github.io/MLMONDAYS/) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_FRI1At8wBj"
   },
   "source": [
    ">A) Live session (***this notebook***): we'll work through jupyter notebooks containing workflows for image recognition (whole image classification). We'll be trying to answer the question, How much of the Texas coastline is developed?. To answer this question, we will train a deep learning model to classify aerial (oblique) images of the Texas coast, categorized into several natural and non-natural landuse/cover classes. See the [data page](https://dbuscombe-usgs.github.io/MLMONDAYS/docs/doc2) for more information on the dataset.\n",
    "\n",
    ">B) Optional class assignment: an additional dataset is provided that you can work on using the same models introduced in the class. The NWPU-RESISC45 is a publicly available benchmark for REmote Sensing Image Scene Classification (RESISC), created by Northwestern Polytechnical University (NWPU). We have curated a version of this dataset covering 11 scene classes. This dataset contains 7,700 images, with 700 images in each class. Participants will also be encouraged to adapt what they learned in the class to their own image recognition problems using their own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "532yLRTDzTKn"
   },
   "source": [
    "## Written by Daniel Buscombe\n",
    "\n",
    "![](https://mardascience.com/wp-content/uploads/2019/06/cropped-MardaScience_logo-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spGxMbPi-tas"
   },
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2020, Marda Science LLC\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5N4MLVnC9dwO"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this lesson, we will train a neural network 'end to end' in an extremely discriminative approach that explicitly maps the classes to the image features, and optimized to extract the features that explicitly predict the class. The network works by linking an image feature extractor to a classifying head, such that feature extraction is limited to only those that help predict the class. The feature extraction therefore results in classification directly. \n",
    "\n",
    "For datasets where classes are obviously distinct, this is an extremely successful approach. We will see this with the NWPU dataset. However, for the TAMUCC dataset, where there is a lot more variability within classes and a lot less variability within classes, we will see how successful this approach is.\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Set up a data workflow to feed the model as it trains\n",
    "  * use batches fed optimally to the GPU from TFRecord files\n",
    "  * use data augmentation as a regularization strategy\n",
    "  * split into train (40% of the data) and validation portions (60%)\n",
    "2. Train it\n",
    "  * use transfer learning to train a classifier\n",
    "  * use a learning rate scheduler to pass variable learning rates to the model as it trains\n",
    "  * use 'early stopping' to base cessation of training on observed plateauing of validation loss\n",
    "  * use a checkpoint to monitor validation loss and save the best model weights when the validation loss improves\n",
    "  * use class weightings to lessen effects of class imbalance\n",
    "3. Evaluate it\n",
    "  * study the model training history - the loss and accuracy curves of train and validation sets\n",
    "  * evaluate the performance of the trained model on the validation set\n",
    "  * plot a 'confusion matrix' of correspondences between actual and estimate class labels\n",
    "  * read some sample images from file, and use the model for prediction \n",
    "4. Look at results from a  similar workflow on different class subsets\n",
    "\n",
    "### Live discussion points\n",
    "* How does this work?\n",
    "* What are the biggest levers on training? (optimizer, learning rate, loss function, augmentation, dropout, model architecture, amount of data, etc)\n",
    "* Why is accuracy better for NWPU data compared to TAMUCC data?\n",
    "* How to apply to your data?\n",
    "* When and how to use transfer learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeObJawC6GYF"
   },
   "source": [
    "### Mini-lecture 2: ML Mondays overview\n",
    "\n",
    "> Slides are [here](https://docs.google.com/presentation/d/1lyZ0YAzP-9pLLTyAuwBgmD7uBO83MkJF1e-Ps3xXlgs/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVBGNUFA9Gba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNyfpjt96YSF"
   },
   "source": [
    "The following notebook is equivalent (in result) to running the following script inside this directory, which you could do by uncommenting and running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXF3ImjiTsQe"
   },
   "outputs": [],
   "source": [
    "# !python tamucc_imrecog_part3c.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZ6feCj5EXjJ"
   },
   "source": [
    "Okay, first we'll define some more variables \n",
    "\n",
    "\n",
    "* `BATCH_SIZE` is the number of image--label pairs you will provide the model during each step of model training. You'll notice how I have made this a function of the image size - the reason is that I'm trying to limit the amount of memory this data will consume on my GPU. Generally speaking, larger batch sizes promote more stable model convergences (i.e. a relatively smooth decreasing loss curve). However, sometimes it is beneficial to have the model see small batches, especially if the model uses batch normalization\n",
    "\n",
    "* `MAX_EPOCHS` is the maximum number of epochs to train models over. This will almost never be reached, because we'll use something called \"early stopping\" that will terminate model training if the validation loss isn't improving (i.e. lowering) after a certain amount of time\n",
    "\n",
    "The following varibles relate to how we will specify the learning rate that the model will use at every model training epoch, known as \"learning rate scheduling\"\n",
    "\n",
    "* `start_lr`. The starting learning rate. I usually specify these as round order of magnitudes e.g. 1e-5 instead of 0.00001\n",
    "* `min_lr`. The minimum learning rate\n",
    "* `max_lr`. The maximum learning rate 1e-3\n",
    "* `rampup_epochs`. The number of epcohs to ramp up to the maximum\n",
    "* `sustain_epochs`. The number of epochs to stay at the maximum\n",
    "* `exp_decay`. The rate of exponential decay (larger numbers = faster rate of decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbMRT0ya9L55"
   },
   "outputs": [],
   "source": [
    "#start with a high validation split. If model poor on train data, can decrease\n",
    "VALIDATION_SPLIT = 0.6\n",
    "\n",
    "#start small - can increase later with larger hardware\n",
    "TARGET_SIZE= 400\n",
    "\n",
    "if TARGET_SIZE==400:\n",
    "   BATCH_SIZE = 6\n",
    "elif TARGET_SIZE==224:\n",
    "   BATCH_SIZE = 16\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "ims_per_shard = 200\n",
    "\n",
    "start_lr = 1e-5 #0.00001\n",
    "min_lr = start_lr\n",
    "max_lr = 1e-3\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiAwK022EYRh"
   },
   "source": [
    "There are a lot of libraries and functions that get imported from `imports.py`. I recommend you look at the contents to see what libraries and functions get imported - there are utilities for file input/output, plotting, making models and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DF385rD5XO-w"
   },
   "source": [
    "Ensure you have `from tamucc_imports import *` uncommented and `from nwpu_imports import *` commented out before running the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "nEY0Hth4ijXx",
    "outputId": "411dba5b-603e-4219-f74f-692f295c8b52"
   },
   "outputs": [],
   "source": [
    "!head -n 33 imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "a4KUn3dFeUsL",
    "outputId": "78ab106e-65e4-417c-9a4e-6e0515217aab"
   },
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGfZnxRZ9f3L"
   },
   "source": [
    "\n",
    "### Train a model to classify 4 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kahu-25GEp2d"
   },
   "source": [
    "We implement a custom deep neural network for classification, based on a MobileNetV2 feature extractor and a further set of layers for feature distillation and classification.\n",
    "\n",
    "The feature extractor based on MobileNetV2 uses weights learned from classifying imagenet classes. It was then trained further on the 4-class TAMUCC subset, without class weights. We initiate the model with those weights. Then train for one last round, to ***fine-tune*** the model to the 4 classes, with class weights that will attempt to ameliorate the issues with unequal numbers of example images per class\n",
    "\n",
    "We define lots of variables:\n",
    "\n",
    "* patience: when training the model, we will use a strategy known as 'early stopping' to decide when to stop model training. It does this by monitoring improvement in the validation loss. If no improvement in validation loss is made over `patience` epochs, model training is terminated early\n",
    "* data_path: where the tfrecord files you wish to use are\n",
    "* json_file: a json format file that lists the classes (optionally, you could hard code them in as a list of strings)\n",
    "* filepath: this is the model weights filepath. This is the .h5 file that contains the trained model weights, and is updated during training\n",
    "* sample_data_path: this is where example jpeg images reside\n",
    "* initial_weights: in this particular example, we are going to employ transfer learning, using weights inherited from a previous model training on the same dataset but with different hyperparameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMpWZR6-8muA"
   },
   "outputs": [],
   "source": [
    "data_path= os.getcwd()+os.sep+\"data/tamucc/full_4class/400\"\n",
    "\n",
    "json_file = os.getcwd()+os.sep+'data/tamucc/full_4class/tamucc_full_4classes.json'\n",
    "\n",
    "filepath = os.getcwd()+os.sep+'results/tamucc_full_4class_mv2_best_weights_model3.h5'\n",
    "\n",
    "sample_data_path= os.getcwd()+os.sep+\"data/tamucc/full_4class/sample\"\n",
    "\n",
    "initial_weights = os.getcwd()+os.sep+'results/tamucc_subset_4class_mv2_best_weights_model2.h5'\n",
    "\n",
    "patience = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrO4xMH-KJKG"
   },
   "source": [
    "These are utility functions that we need to create train, validation, and evaluation (test) data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJJMG333P_bH"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "def get_training_dataset():\n",
    "    \"\"\"\n",
    "    This function will return a batched dataset for model training\n",
    "    INPUTS: None\n",
    "    OPTIONAL INPUTS: None\n",
    "    GLOBAL INPUTS: training_filenames\n",
    "    OUTPUTS: batched data set object\n",
    "    \"\"\"\n",
    "    return get_batched_dataset(training_filenames)\n",
    "\n",
    "def get_validation_dataset():\n",
    "    \"\"\"\n",
    "    This function will return a batched dataset for model training\n",
    "    INPUTS: None\n",
    "    OPTIONAL INPUTS: None\n",
    "    GLOBAL INPUTS: validation_filenames\n",
    "    OUTPUTS: batched data set object\n",
    "    \"\"\"\n",
    "    return get_batched_dataset(validation_filenames)\n",
    "\n",
    "def get_validation_eval_dataset():\n",
    "    \"\"\"\n",
    "    This function will return a batched dataset for model training\n",
    "    INPUTS: None\n",
    "    OPTIONAL INPUTS: None\n",
    "    GLOBAL INPUTS: validation_filenames\n",
    "    OUTPUTS: batched data set object\n",
    "    \"\"\"\n",
    "    return get_eval_dataset(validation_filenames)\n",
    "\n",
    "#-----------------------------------\n",
    "def get_aug_datasets():\n",
    "    \"\"\"\n",
    "    This function will create train and validation sets based on a specific\n",
    "    data augmentation pipeline consisting of random flipping, small rotations,\n",
    "    translations and contrast adjustments\n",
    "    INPUTS: None\n",
    "    OPTIONAL INPUTS: None\n",
    "    GLOBAL INPUTS: validation_filenames, training_filenames\n",
    "    OUTPUTS: two batched data set objects, one for training and one for validation\n",
    "    \"\"\"\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomRotation(0.01),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1,0.1),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomContrast(0.1)\n",
    "    ])\n",
    "\n",
    "    augmented_train_ds = get_training_dataset().map(\n",
    "      lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "    augmented_val_ds = get_validation_dataset().map(\n",
    "      lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    return augmented_train_ds, augmented_val_ds\n",
    "\n",
    "#-----------------------------------\n",
    "def get_all_labels(nb_images, VALIDATION_SPLIT, BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    \"get_all_labels\"\n",
    "    This function will obtain the classes of all samples in both train and\n",
    "    validation sets. For computing class imbalance on the whole dataset\n",
    "    INPUTS:\n",
    "        * nb_images [int]: number of total images\n",
    "    OPTIONAL INPUTS: None\n",
    "    GLOBAL INPUTS: VALIDATION_SPLIT, BATCH_SIZE\n",
    "    OUTPUTS:\n",
    "        * l [list]: list of integers representing labels of each image\n",
    "    \"\"\"\n",
    "    l = []\n",
    "    num_batches = int(((1-VALIDATION_SPLIT) * nb_images) / BATCH_SIZE)\n",
    "    train_ds = get_training_dataset()\n",
    "    for _,lbls in train_ds.take(num_batches):\n",
    "        l.append(lbls.numpy())\n",
    "\n",
    "    val_ds = get_validation_dataset()\n",
    "    num_batches = int(((VALIDATION_SPLIT) * nb_images) / BATCH_SIZE)\n",
    "    for _,lbls in val_ds.take(num_batches):\n",
    "        l.append(lbls.numpy())\n",
    "\n",
    "    l = np.asarray(l).flatten()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOczZ3U-Eqfs"
   },
   "source": [
    "We get a list of filenames, read the CLASSES from the provided json file\n",
    "\n",
    "Then we compute the variables we need to pass to model training, including the number of training and validation steps, training and validation datasets to feed to the model while it trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "bOfTHeKx9AYB",
    "outputId": "5ad9d0e7-6311-45b3-923b-74ea62ac5ba4"
   },
   "outputs": [],
   "source": [
    "filenames = sorted(tf.io.gfile.glob(data_path+os.sep+'*.tfrec'))\n",
    "\n",
    "CLASSES = read_classes_from_json(json_file)\n",
    "print(CLASSES)\n",
    "\n",
    "nb_images = ims_per_shard * len(filenames)\n",
    "print(nb_images)\n",
    "\n",
    "split = int(len(filenames) * VALIDATION_SPLIT)\n",
    "\n",
    "training_filenames = filenames[split:]\n",
    "validation_filenames = filenames[:split]\n",
    "\n",
    "validation_steps = int(nb_images // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
    "steps_per_epoch = int(nb_images // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
    "\n",
    "print(steps_per_epoch)\n",
    "print(validation_steps)\n",
    "\n",
    "train_ds = get_training_dataset()\n",
    "\n",
    "val_ds = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvHbPjIlLH8R"
   },
   "source": [
    "Let's take a look at a batch, drawn from the dataset. You'll notice that the imagery is dark - that is because it has been standardized (each image has its mean value substracted, then it is normalized by the standard deviation of the original image). This makes the pixel values scale between -1 and 1. The matplotlib `imshow` command is only showing the positive values, hence the general darkness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "QhERw_4ojeO2",
    "outputId": "e9770721-dd45-412e-f3b7-e69ece28e84a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for imgs,lbls in train_ds.take(1):\n",
    "  for count,im in enumerate(imgs):\n",
    "     plt.subplot(int(BATCH_SIZE/2),int(BATCH_SIZE/2),count+1)\n",
    "     plt.imshow(im)\n",
    "     plt.title(CLASSES[lbls.numpy()[count]], fontsize=8)\n",
    "     plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-DV-xm0_LkJP"
   },
   "source": [
    "We do the same for a batch of the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "sqeRDJqijhq7",
    "outputId": "247901f1-5f0a-4f3e-b1a7-395b5219dbbd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for imgs,lbls in val_ds.take(1):\n",
    "  for count,im in enumerate(imgs):\n",
    "     plt.subplot(int(BATCH_SIZE/2),int(BATCH_SIZE/2),count+1)\n",
    "     plt.imshow(im)\n",
    "     plt.title(CLASSES[lbls.numpy()[count]], fontsize=8)\n",
    "     plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2QKoUBeTW61"
   },
   "source": [
    "Data augmentation is typically used to train modern deep neural networks. The primary purpose is ***regularization***\n",
    "\n",
    "We use the `Dataset.map` functionality to create a dataset that yields batches of augmented images. In this case, data augmentation will happen asynchronously on the CPU. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xyImTfxEswA"
   },
   "source": [
    "Next we apply our augmentation procedure to each dataset, and show examples from the augmented training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "colab_type": "code",
    "id": "QsfRiwvW9AaV",
    "outputId": "5715b657-ecfb-49d8-f742-e060b4b08273"
   },
   "outputs": [],
   "source": [
    "augmented_train_ds, augmented_val_ds = get_aug_datasets()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "for im,l in augmented_train_ds.take(1):\n",
    "    for count,im in enumerate(im):\n",
    "       plt.subplot(int(BATCH_SIZE/2),int(BATCH_SIZE/2),count+1)\n",
    "       plt.imshow(im)\n",
    "       plt.title(CLASSES[l[count]], fontsize=8)\n",
    "       plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_x-st-3GEtS1"
   },
   "source": [
    "This function reads all labels from both test and validation datasets\n",
    "\n",
    "then makes a quick histogram of the relative frequency of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twYgNoA3L0FR"
   },
   "outputs": [],
   "source": [
    "l = get_all_labels(nb_images, VALIDATION_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "colab_type": "code",
    "id": "vuE3BSfYOdlB",
    "outputId": "9eea27d5-fdaf-4fc9-fad9-a501873275af"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(l, bins=np.arange(len(CLASSES)+1), rwidth=.2)\n",
    "plt.gca().set_xticks([.5,1.5,2.5,3.5])\n",
    "plt.gca().set_xticklabels([c.decode() for c in CLASSES])\n",
    "plt.ylabel('Number of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_CltqvnL0Wu"
   },
   "source": [
    "It shows class imbalance - we will try to counter the effects of this during model traiing by computing per-class weights\n",
    "\n",
    "Scikit-learn provide a handy utility for this occasion, called `class_weight`\n",
    "\n",
    "Per-class weights will be given by number of images divided by the product of the number of classes and the frequency of the class. SO, they will vary inversely with the frequency of the class in the entire dataset. The loss function will be weighted less for these classes, reducing the tendency of the model to estimate the most frequenct class. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KW00EFw39Ac6",
    "outputId": "4c955300-946c-4410-f018-6ccdf027d533"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(l),\n",
    "                                                 l)\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose a model\n",
    "\n",
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/practices-model.png)\n",
    "\n",
    "\n",
    "### How to set things up\n",
    "\n",
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/practices.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZH1V8otQ7bj"
   },
   "source": [
    "Next we create a model instance, compile it, and define callbacks.\n",
    "\n",
    "The model is called `transfer_learning_mobilenet_model` because it is based on a generic deep learning feature extractor (MobileNetV2), initialized using weights from the same model trained to classify imagenet imagery and classes. This transfer of weights from one model to another is an example of transfer learning.\n",
    "\n",
    "In fact in this case the model was already trained on this dataset, so we load the weights from the previous model training. \n",
    "\n",
    "We define an `EarlyStopping` object to pass to the model `.fit()` function as a callback function. It monitors validation loss, and stops training if the loss hasn't improved for `patience` epochs (defined above)\n",
    "\n",
    "Next we make a `ModelCheckpoint` to save model weights to `filepath` when validaton loss improves. This therefore keeps track and saves the \"best only\" weights\n",
    "\n",
    "The final callback is the `LearningRateScheduler` that dictates to the model what learning rate to use, depending on epoch number. It calls a custom learning rate scheduler function, `lrfn` (defined in `imports.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "jPCEDOQiW9g1",
    "outputId": "d72ca924-f220-48a0-c57a-dfa8b56cd9f7"
   },
   "outputs": [],
   "source": [
    "model = transfer_learning_mobilenet_model(len(CLASSES), (TARGET_SIZE, TARGET_SIZE, 3), dropout_rate=0.5)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## transfer learning\n",
    "model.load_weights(initial_weights)\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\",\n",
    "                              mode=\"min\", patience=patience)\n",
    "\n",
    "# set checkpoint file\n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss',\n",
    "                                verbose=0, save_best_only=True, mode='min',\n",
    "                                save_weights_only = True)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
    "\n",
    "callbacks = [model_checkpoint, earlystop, lr_callback]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAAcLAzpSw79"
   },
   "source": [
    "Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-GcVe0hT8Kl"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCj7q8X2Sz2d"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zycAXVK-EvnT"
   },
   "source": [
    "If `do_train` is `True`, the model will train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3-RiXYrQCxQ"
   },
   "outputs": [],
   "source": [
    "do_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gMkL9l8Vk661",
    "outputId": "d465c2cd-de5a-4921-d62f-e5e4dbda834d"
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "\n",
    "  history = model.fit(train_ds, steps_per_epoch=steps_per_epoch, epochs=MAX_EPOCHS,\n",
    "                        validation_data=val_ds, validation_steps=validation_steps,\n",
    "                        callbacks=callbacks, class_weight = class_weights)\n",
    "\n",
    "  K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vd9yZaaOQl4Y"
   },
   "source": [
    "If not training, just load the previously trained model weights straight into the model (the beauty of keras!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsWJb1kUQMz6"
   },
   "outputs": [],
   "source": [
    "if not do_train:\n",
    "  model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stLULYswY9dF"
   },
   "source": [
    "> How to train models?\n",
    "\n",
    "Access the slides [here](https://docs.google.com/presentation/d/1p7lDv3RoRzaW3U6n0KsOOui0zsEb9c8gzZGfgn-9_98/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfMZnjfU9gFx"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "When the model is trained, we will evaluate it in a variety of ways using unseen test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQoguQJuTpd0"
   },
   "source": [
    "First let's take a look at the model training history, to see how fast and variabily in convergenced to a solution\n",
    "\n",
    "The plot on the left shows the training and validation accuracy over training epoch, and the right plot shows the correspodning loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "9MV3QezqY10m",
    "outputId": "ba338482-d879-4866-c529-1e6aab6f15b9"
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "  n = len(history.history['accuracy'])\n",
    "\n",
    "  plt.figure(figsize=(20,10))\n",
    "  plt.subplot(121)\n",
    "  plt.plot(np.arange(1,n+1), history.history['accuracy'], 'b', label='train accuracy')\n",
    "  plt.plot(np.arange(1,n+1), history.history['val_accuracy'], 'k', label='validation accuracy')\n",
    "  plt.xlabel('Epoch number', fontsize=10); plt.ylabel('Accuracy', fontsize=10)\n",
    "  plt.legend(fontsize=10)\n",
    "\n",
    "  plt.subplot(122)\n",
    "  plt.plot(np.arange(1,n+1), history.history['loss'], 'b', label='train loss')\n",
    "  plt.plot(np.arange(1,n+1), history.history['val_loss'], 'k', label='validation loss')\n",
    "  plt.xlabel('Epoch number', fontsize=10); plt.ylabel('Loss', fontsize=10)\n",
    "  plt.legend(fontsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/evaluate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJd5GcwiEyAE"
   },
   "source": [
    "Use the handy `.evaluate()` function of the model object to compute the average accuracy over the entire validation dataset, and display the mean accuracy in percent\n",
    "\n",
    "(note that Dropout are inactive at inference time, so that layer won't affect our model results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "bGbupq1L9Ah3",
    "outputId": "9b3fea2f-03a0-45b5-b98d-8122917d5d90"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(get_validation_eval_dataset(), batch_size=BATCH_SIZE)\n",
    "print('Test Mean Accuracy: ', round((accuracy)*100, 2),' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/predict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsHmbTbWEylf"
   },
   "source": [
    "Get a list of filenames to test the model on, from the provided `sample_data_path`, and make a plot of each image. The title of each subplot is the actual class name, and the coloured box is the model's estimate. Green boxes indicate \"correct\" model estimate, and red boxes indicates \"incorrect\" model estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "colab_type": "code",
    "id": "qX_91-nD8mw9",
    "outputId": "799a996a-4ea1-46f1-8691-e0b6f8213078"
   },
   "outputs": [],
   "source": [
    "sample_filenames = sorted(tf.io.gfile.glob(sample_data_path+os.sep+'*.jpg'))\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "for counter,f in enumerate(sample_filenames):\n",
    "    image, im = file2tensor(f, 'mobilenet')\n",
    "    plt.subplot(6,4,counter+1)\n",
    "    name = sample_filenames[counter].split(os.sep)[-1].split('_IMG')[0]\n",
    "    plt.title(name, fontsize=10)\n",
    "    plt.imshow(tf.cast(image, tf.uint8))\n",
    "    plt.axis('off')\n",
    "\n",
    "    scores = model.predict(tf.expand_dims(im, 0) , batch_size=1)\n",
    "    n = np.argmax(scores[0])\n",
    "    est_name = CLASSES[n].decode()\n",
    "    if name==est_name:\n",
    "       plt.text(10,50,'prediction: %s' % est_name,\n",
    "                color='k', fontsize=8,\n",
    "                ha=\"center\", va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(.1, 1., .5),\n",
    "                       fc=(.1, 1., .5),\n",
    "                       ))\n",
    "    else:\n",
    "       plt.text(10,50,'prediction: %s' % est_name,\n",
    "                color='k', fontsize=8,\n",
    "                ha=\"center\", va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round\",\n",
    "                       ec=(1., 0.5, 0.1),\n",
    "                       fc=(1., 0.8, 0.8),\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uP1j2-hE0Jd"
   },
   "source": [
    "Finally, we are going to compute and show the confusion matrix\n",
    "\n",
    "We analyze the entire validation set using `get_label_pairs`, which collates all true labels and uses the model to estimate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKTsvx808mzp"
   },
   "outputs": [],
   "source": [
    "val_ds = get_validation_eval_dataset()\n",
    "\n",
    "labs, preds = get_label_pairs(val_ds, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6AjVJTTVESA"
   },
   "source": [
    "We use the scikit-learn utility `confusion_matrix` to compute the confusion matrix from the true labels `labs` and the model estimates `preds`. The values are normalized by row sums, values less than `thres` are zeroed out, and the matrix is plotted as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VSfbk7Dedbfd",
    "outputId": "382e790c-c9ea-4190-98e4-cf0f9004a2d7"
   },
   "outputs": [],
   "source": [
    "thres = 0.1\n",
    "cm = confusion_matrix(labs, preds)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "cm[cm<thres] = 0\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(cm,\n",
    "    annot=True,\n",
    "    cmap = sns.cubehelix_palette(dark=0, light=1, as_cmap=True))\n",
    "\n",
    "tick_marks = np.arange(len(CLASSES))+.5\n",
    "plt.xticks(tick_marks, [c.decode() for c in CLASSES], rotation=45,fontsize=12)\n",
    "plt.yticks(tick_marks, [c.decode() for c in CLASSES],rotation=45, fontsize=12)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1RsGIajJ47i"
   },
   "source": [
    "### Discussion points\n",
    "\n",
    "* How does this work?\n",
    "* What are the biggest levers on training? (optimizer, learning rate, loss function, augmentation, dropout, model architecture, amount of data, etc)\n",
    "* Why is accuracy better for NWPU data compared to TAMUCC data?\n",
    "* How to apply to your data?\n",
    "* When and how to use transfer learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/overkill.png)\n",
    "\n",
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/overeffort.png)\n",
    "\n",
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/overfitting.png)\n",
    "\n",
    "![](https://raw.githubusercontent.com/dbuscombe-usgs/MLMONDAYS/master/1_ImageRecog/notebooks/assets/avoid_overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dpg7Qh1CdviX"
   },
   "source": [
    "## Full TAMUCC Case study\n",
    "\n",
    "There are several versions of the data. There are 2- and 3-class versions as well as the 4-class version we have just seen. These workflows highlight different strategies for model building including:\n",
    "\n",
    "* transfer learning\n",
    "* fine-tuning\n",
    "* class-weighting\n",
    "* custom versus 'stock' models\n",
    "\n",
    "### 2-class ('developed', 'undeveloped')\n",
    "\n",
    "#### Script 1. tamucc_imrecog_part1a.py\n",
    "\n",
    "Implements a custom deep neural network for classification, on the data subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3OFmCmtgr84"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "q9tbwyeShO4a",
    "outputId": "dfb6b0ec-1c86-4ec6-9390-83838f9f3d0d"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_2class_mv2_model1_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNme7JjRhSoC"
   },
   "source": [
    "\n",
    "#### Script 2. tamucc_imrecog_part1b.py\n",
    "\n",
    "Implements a custom deep neural network for classification, trained using class weights (a measure of the relative proportion of each class in the dataset), on the data subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "o-rqmyksgmPv",
    "outputId": "a6b3e4b6-2b45-4bbd-df6b-88753d29b9bb"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_2class_mv2_model2_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8iPDvPShU39"
   },
   "source": [
    "\n",
    "#### Script 3. tamucc_imrecog_part1c.py\n",
    "\n",
    "Implements a custom deep neural network for classification, trained using class weights (a measure of the relative proportion of each class in the dataset), on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "_J0Ck278hVDf",
    "outputId": "26a7a986-d0ae-41b4-836d-4c4e6d9bd312"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_full_sample_2class_mv2_model2_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xL680qGIhVLj"
   },
   "source": [
    "\n",
    "### 3-class ('marsh', 'developed', 'other')\n",
    "\n",
    "#### Script 1. tamucc_imrecog_part2a.py\n",
    "\n",
    "Implements a custom deep neural network for classification on the data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "HLMR4t_DhVSb",
    "outputId": "12bbca20-e12e-4bbf-a43c-cfc2a421b3c6"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_3class_custom_model_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjjDlzVBhVa_"
   },
   "source": [
    "#### Script 2. tamucc_imrecog_part2b.py\n",
    "\n",
    "Implements a model based on mobilenetV2, trained using weights learned from another dataset (specifically, \"imagenet\") - this is called transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "2k4fKPU-hVgw",
    "outputId": "6eadddea-e8c9-4948-a5c4-cc19ef46461e"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_3class_mv2_model2_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SA5ekxfIjV_R"
   },
   "source": [
    "#### Script 2. tamucc_imrecog_part2c.py\n",
    "\n",
    "Takes the model trained in `tamucc_imrecog_part2b.py`, and fine-tunes it. This means the lower layers are frozen, and the upper layers are tuned with a smaller learning rate. This is an optimization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "lEqfb1NzjWHC",
    "outputId": "0d4f3948-bcb0-45e2-dd94-7c71f96f4472"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_3class_mv2_model3_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PurrbB3Yh2mW"
   },
   "source": [
    "\n",
    "### 4-class ('sand beaches', 'gravel beaches', 'marshes', and 'manmade')\n",
    "\n",
    "#### Script 1. tamucc_imrecog_part3a.py\n",
    "\n",
    "Implements a model based on mobilenetV2, trained using weights learned from another dataset (specifically, \"imagenet\") - this is called transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "GPGDjZZih2ux",
    "outputId": "b65d137f-1937-4b16-a91e-6fa52d633a1a"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_4class_mv2_model1_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lSO42uYh20z"
   },
   "source": [
    "#### Script 2. tamucc_imrecog_part3b.py\n",
    "\n",
    "Same model as above, this time trained using class weights (a measure of the relative proportion of each class in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "brFOGm1zh27L",
    "outputId": "de8d9b54-c445-4e5b-df58-a65469ff2b98"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_sample_4class_mv2_model2_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nPO2oaFh9vy"
   },
   "source": [
    "#### Script 3. tamucc_imrecog_part3c.py\n",
    "\n",
    "This is a reproduction of the workflow presented here earlier on\n",
    "\n",
    "Implements a model based on mobilenetV2, trained using weights learned from another dataset (specifically, \"imagenet\"), on the full dataset\n",
    "\n",
    "3 out of 4 classes are accurate (>90%) but the model gets confused between gravel/shell beaches and marshes about a third of the time. Examination of this imagery reveals why; often the coarse beaches front marshes, and both are visible in the scene. Greater specificity in class creation is likely required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "UwMNMVRflcLk",
    "outputId": "53081060-ba72-4e44-c552-4e407764e600"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/tamucc_full_4class_mv2_model3_cm_val.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HU2ZTeL2o9DM"
   },
   "source": [
    "### Data generation workflows\n",
    "\n",
    "The three functions below are included to demonstrate how the datasets were constructed from folders of images\n",
    "\n",
    "> tamucc_make_tfrecords_sample_2class.py\n",
    "\n",
    "> tamucc_make_tfrecords_sample_3class.py\n",
    "\n",
    "> tamucc_make_tfrecords_sample_4class.py\n",
    "\n",
    "The NWPU dataset was generated using\n",
    "\n",
    "> nwpu_make_tfrecords.py\n",
    "\n",
    "I also wrote a [blog post](https://dbuscombe-usgs.github.io/MLMONDAYS/blog/2020/09/01/blog-post) about how to do this. Between these examples, you should be able to adapt this similar workflow for your own data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaQK6-n6KYMy"
   },
   "source": [
    "## NWPU Case study\n",
    "\n",
    "There is only one version of the data; 224 pixel imagery and 11 classes. However, you can apply what you have learned in this lesson \n",
    "\n",
    "#### Script: nwpu_imrecog_part1.py\n",
    "\n",
    "Implements a custom deep neural network for classification, just as in this lesson, based on a mobilenet V2 feature extractor and a further set of layers for feature distillation and classification\n",
    "\n",
    "This workflow results in a confusion matrix like this, showing high accuracy of prediction for all classes - a good result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5GB2Z1_lgF6"
   },
   "outputs": [],
   "source": [
    "Image(filename = os.getcwd()+os.sep + \"results/nwpu_sample_11class_mv2_model1_cm_val.png\", width=500, height=500)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MLMondays_week1_live_partB_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
